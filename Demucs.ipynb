{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary step: Install and Import Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: IPython in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (9.2.0)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.7.0)\n",
      "Requirement already satisfied: torchaudio in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.7.0)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (3.10.3)\n",
      "Requirement already satisfied: librosa in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.11.0)\n",
      "Requirement already satisfied: torchmetrics in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.7.2)\n",
      "Requirement already satisfied: norbert in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (0.2.1)\n",
      "Requirement already satisfied: decorator in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (4.13.2)\n",
      "Requirement already satisfied: wcwidth in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->-r requirements.txt (line 1)) (0.2.13)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (2025.5.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from librosa->-r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from librosa->-r requirements.txt (line 7)) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from librosa->-r requirements.txt (line 7)) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from librosa->-r requirements.txt (line 7)) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from librosa->-r requirements.txt (line 7)) (1.5.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from librosa->-r requirements.txt (line 7)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from librosa->-r requirements.txt (line 7)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from librosa->-r requirements.txt (line 7)) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from librosa->-r requirements.txt (line 7)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from librosa->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from torchmetrics->-r requirements.txt (line 8)) (0.14.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from jedi>=0.16->IPython->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics->-r requirements.txt (line 8)) (78.1.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 7)) (0.44.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from pexpect>4.3->IPython->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 7)) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 7)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (2025.4.26)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 7)) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 7)) (2.22)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/miniconda3/envs/MAE_Selected_Topics/lib/python3.11/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from torchmetrics.audio import ScaleInvariantSignalDistortionRatio\n",
    "import norbert\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of the Model and Device Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HDemucs(\n",
       "  (freq_encoder): ModuleList(\n",
       "    (0): _HEncLayer(\n",
       "      (conv): Conv2d(4, 48, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): _HEncLayer(\n",
       "      (conv): Conv2d(48, 96, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): _HEncLayer(\n",
       "      (conv): Conv2d(96, 192, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): _HEncLayer(\n",
       "      (conv): Conv2d(192, 384, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): _HEncLayer(\n",
       "      (conv): Conv2d(384, 768, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): _HEncLayer(\n",
       "      (conv): Conv1d(768, 1536, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv1d(1536, 3072, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (freq_decoder): ModuleList(\n",
       "    (0): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(1536, 768, kernel_size=(4,), stride=(2,))\n",
       "      (norm2): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv1d(1536, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (1): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(768, 384, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv2d(768, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (2): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(384, 192, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (3): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(192, 96, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (4): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(96, 48, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (5): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(48, 16, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (time_encoder): ModuleList(\n",
       "    (0): _HEncLayer(\n",
       "      (conv): Conv1d(2, 48, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(48, 96, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): _HEncLayer(\n",
       "      (conv): Conv1d(48, 96, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): _HEncLayer(\n",
       "      (conv): Conv1d(96, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): _HEncLayer(\n",
       "      (conv): Conv1d(192, 384, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): _HEncLayer(\n",
       "      (conv): Conv1d(384, 768, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Identity()\n",
       "      (norm2): Identity()\n",
       "      (dconv): Identity()\n",
       "    )\n",
       "  )\n",
       "  (time_decoder): ModuleList(\n",
       "    (0): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(768, 384, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "      (rewrite): Identity()\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (1): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (2): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(192, 96, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(192, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (3): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(96, 48, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(96, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (4): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(48, 8, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(48, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (freq_emb): _ScaledEmbedding(\n",
       "    (embedding): Embedding(512, 48)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle = torchaudio.pipelines.HDEMUCS_HIGH_MUSDB_PLUS\n",
    "model = bundle.get_model()\n",
    "sample_rate = bundle.sample_rate\n",
    "\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # windows\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") # macOS\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of the Dataset and Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset at: https://zenodo.org/records/3338373"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_LENGTH = 30  # 30 seconds of audio from each song\n",
    "DATASET_FOLDER =  \"./musdb18hq/test\" # dataset should be inside the project folder\n",
    "DATASET_FOLDER_TRIMMED = \"./musdb18hq_trimmed\" # trimmed dataset will be saved here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary creation\n",
    "\n",
    "(Dataset Structure: `{track_folder -> {stem_name -> waveform}`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_non_silence_start(song):\n",
    "    \"\"\"\n",
    "    Given a song (dictionary of stem names -> waveform),\n",
    "    use librosa.effects.trim to find the starting index of non-silent \n",
    "    segments for each stem and return the highest start index.\n",
    "    \"\"\"\n",
    "    max_start = 0\n",
    "    for stem, waveform in song.items():\n",
    "        # Convert tensor waveform to numpy if necessary\n",
    "        if hasattr(waveform, \"detach\"):\n",
    "            waveform_np = waveform.detach().cpu().numpy()\n",
    "        else:\n",
    "            waveform_np = waveform\n",
    "        \n",
    "        # If waveform is multi-channel (shape: channels x samples)\n",
    "        if waveform_np.ndim > 1:\n",
    "            # Convert to mono using librosa.to_mono\n",
    "            waveform_np = librosa.to_mono(waveform_np)\n",
    "        else:\n",
    "            waveform_np = waveform_np.squeeze()\n",
    "\n",
    "        # Trim leading and trailing silence\n",
    "        # trim returns a tuple (trimmed_audio, (start, end))\n",
    "        trimmed, indices = librosa.effects.trim(waveform_np)\n",
    "        if indices.size and indices[0] > max_start:\n",
    "            max_start = indices[0]\n",
    "            \n",
    "    return max_start\n",
    "def is_stem_silent(waveform, threshold=1e-4):\n",
    "    \"\"\"\n",
    "    Determines if a given song stem is not silent.\n",
    "    \n",
    "    Args:\n",
    "        waveform (torch.Tensor or np.ndarray): The audio waveform of the stem.\n",
    "        threshold (float): The amplitude threshold below which the stem is considered silent.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the stem is not silent, False otherwise.\n",
    "    \"\"\"\n",
    "    # Convert tensor waveform to numpy if necessary\n",
    "    if hasattr(waveform, \"detach\"):\n",
    "        waveform = waveform.detach().cpu().numpy()\n",
    "    \n",
    "    # If waveform is multi-channel (shape: channels x samples), convert to mono\n",
    "    if waveform.ndim > 1:\n",
    "        waveform = librosa.to_mono(waveform)\n",
    "    \n",
    "    # Check if the maximum absolute amplitude exceeds the threshold\n",
    "    return np.max(np.abs(waveform)) < threshold\n",
    "def load_and_process_dataset():\n",
    "    \"\"\"\n",
    "    Load the dataset from the specified folder.\n",
    "    Each subfolder in the dataset corresponds to a song.\n",
    "    Each song contains multiple stems (e.g., mixture, drums, bass, etc.).\n",
    "    Returns:\n",
    "        dataset_dict (dict): A dictionary where keys are track folders and values are dictionaries of stems.\n",
    "    \"\"\"\n",
    "\n",
    "    # sorted list of folders in the dataset\n",
    "    track_folders = sorted(\n",
    "        folder for folder in os.listdir(DATASET_FOLDER)\n",
    "        if os.path.isdir(os.path.join(DATASET_FOLDER, folder))\n",
    "    )\n",
    "\n",
    "    # Dictionary to store {track_folder -> {stem_name -> waveform}}\n",
    "    dataset_dict = {}\n",
    "\n",
    "    # Each subfolder in musdb18hq/test corresponds to a song\n",
    "    for track_folder in tqdm(track_folders):\n",
    "        track_path = os.path.join(DATASET_FOLDER, track_folder)\n",
    "        if not os.path.isdir(track_path):\n",
    "            continue\n",
    "\n",
    "        # Prepare a sub-dictionary for this song\n",
    "        stems_dict = {}\n",
    "        stem_names = [\"mixture\", \"drums\", \"bass\", \"vocals\", \"other\"]\n",
    "        \n",
    "        for stem_name in stem_names:\n",
    "            file_path = os.path.abspath(os.path.join(track_path, f\"{stem_name}.wav\"))\n",
    "            \n",
    "            if not os.path.isfile(file_path):\n",
    "                print(f\"Warning: file not found {file_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load full audio\n",
    "            # print(f\"Loading {track_folder}\" + f\" - {stem_name}\")\n",
    "            waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "            stems_dict[stem_name] = waveform\n",
    "        \n",
    "        max_start = get_max_non_silence_start(stems_dict)\n",
    "\n",
    "        # If the stem is silent, remove it from the dictionary else trim it\n",
    "        for stem_name, waveform in stems_dict.items():\n",
    "            if is_stem_silent(waveform) or waveform.shape[1] < SEGMENT_LENGTH * sample_rate + max_start:\n",
    "                print(f\"Removing silent stem: {stem_name}\")\n",
    "                del stems_dict[stem_name]\n",
    "            else:\n",
    "                # Trim the waveform to the max_start to segment samples\n",
    "                duration = SEGMENT_LENGTH * sample_rate + max_start\n",
    "                stems_dict[stem_name] = waveform[:, max_start:duration]\n",
    "\n",
    "        dataset_dict[track_folder] = stems_dict\n",
    "\n",
    "    return dataset_dict\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load the dataset from the DATASET_FOLDER_TRIMMED folder.\n",
    "    Each subfolder in the dataset corresponds to a song.\n",
    "    Each song contains multiple stems (e.g., mixture, drums, bass, etc.).\n",
    "    Returns:\n",
    "        dataset_dict (dict): A dictionary where keys are track folders and values are dictionaries of stems.\n",
    "    \"\"\"\n",
    "    dataset_dict = {}\n",
    "\n",
    "    for track_folder in tqdm(os.listdir(DATASET_FOLDER_TRIMMED)):\n",
    "        track_path = os.path.join(DATASET_FOLDER_TRIMMED, track_folder)\n",
    "        if not os.path.isdir(track_path):\n",
    "            continue\n",
    "\n",
    "        # Prepare a sub-dictionary for this song\n",
    "        stems_dict = {}\n",
    "        \n",
    "        for stem_name in [\"mixture\", \"drums\", \"bass\", \"vocals\", \"other\", \"new_mixture\"]:\n",
    "            file_path = os.path.abspath(os.path.join(track_path, f\"{stem_name}.wav\"))\n",
    "            \n",
    "            if not os.path.isfile(file_path):\n",
    "                print(f\"Warning: file not found {file_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load full audio\n",
    "            waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "            stems_dict[stem_name] = waveform\n",
    "            \n",
    "        dataset_dict[track_folder] = stems_dict\n",
    "        \n",
    "    return dataset_dict\n",
    "\n",
    "def create_dataset(dataset_dict):\n",
    "    \"\"\"\n",
    "    Create a dataset of trimmed audio files from the musdb18hq dataset.\n",
    "    The dataset is saved in the DATASET_FOLDER_TRIMMED folder.\n",
    "    It processes each track folder, saves the stems as individual files,\n",
    "    and generates a new_mixture file as the sum of the stems.\n",
    "    Args:\n",
    "        dataset_dict (dict): A dictionary where keys are track folders and values are dictionaries of stems.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for track_folder, stems_dict in tqdm(dataset_dict.items()):\n",
    "    \n",
    "        track_path = os.path.join(DATASET_FOLDER_TRIMMED, track_folder)\n",
    "        os.makedirs(track_path, exist_ok=True)\n",
    "        \n",
    "        # Add new_mixture file to the track folder as the sum of the stems\n",
    "        new_mixture = torch.zeros((2, SEGMENT_LENGTH * sample_rate))\n",
    "        for stem_name, waveform in stems_dict.items():\n",
    "            \n",
    "            file_path = os.path.join(track_path, f\"{stem_name}.wav\")\n",
    "            torchaudio.save(file_path, waveform, sample_rate=sample_rate)\n",
    "\n",
    "            # Generation of the new_mixture file\n",
    "            if stem_name != \"mixture\":\n",
    "                new_mixture += waveform\n",
    "\n",
    "        # make the new_mixture the same loudness as the original mixture\n",
    "        if \"mixture\" in stems_dict:\n",
    "            original_mixture = stems_dict[\"mixture\"]\n",
    "\n",
    "            # Scale the new mixture to match the volume of the original mixture\n",
    "            original_max_value = torch.max(torch.abs(original_mixture))\n",
    "            new_max_value = torch.max(torch.abs(new_mixture))\n",
    "            if new_max_value > 0:\n",
    "                new_mixture *= (original_max_value / new_max_value)\n",
    "        else:\n",
    "            # If there is no original mixture, just normalize the new_mixture\n",
    "            new_mixture = new_mixture / torch.max(torch.abs(new_mixture))\n",
    "\n",
    "\n",
    "        # Raise an error if the new_mixture is not normalized\n",
    "        if torch.max(torch.abs(new_mixture)) > 1:\n",
    "            # delete dataset folder if error occurs\n",
    "            if os.path.isdir(DATASET_FOLDER_TRIMMED):\n",
    "                print(f\"Deleting dataset folder {DATASET_FOLDER_TRIMMED} due to error.\")\n",
    "                shutil.rmtree(DATASET_FOLDER_TRIMMED)\n",
    "\n",
    "            raise ValueError(f\"new_mixture for {track_folder} is not normalized. Max value: {torch.max(torch.abs(new_mixture))}\")\n",
    "        \n",
    "        \n",
    "        # Trim the new_mixture to the desired length\n",
    "        new_mixture = new_mixture[:, :SEGMENT_LENGTH * sample_rate]\n",
    "        new_mixture_path = os.path.join(track_path, \"new_mixture.wav\")\n",
    "        torchaudio.save(new_mixture_path, new_mixture, sample_rate)\n",
    "        #print(f\"Saved new mixture to {new_mixture_path}\")\n",
    "        \n",
    "        # Add the new_mixture to stems_dict and update dataset_dict\n",
    "        stems_dict[\"new_mixture\"] = new_mixture\n",
    "        dataset_dict[track_folder] = stems_dict  # Update the dataset_dict explicitly\n",
    "        #print(f\"Added new_mixture to stems_dict for track {track_folder}\")\n",
    "\n",
    "\n",
    "def load_or_create_trimmed_dataset():\n",
    "    \"\"\"\n",
    "    Load or create the trimmed dataset.\n",
    "    If the dataset already exists, it loads the dataset from the musdb18hq_trimmed folder.\n",
    "    If the dataset does not exist, it processes the musdb18hq/test folder and saves the trimmed dataset.\n",
    "    Returns:\n",
    "        dataset_dict (dict): A dictionary where keys are track folders and values are dictionaries of stems.\n",
    "    \"\"\"\n",
    "    # Check if the trimmed dataset already exists\n",
    "    if os.path.isdir(DATASET_FOLDER_TRIMMED):\n",
    "        print(\"Dataset already exists.\")\n",
    "\n",
    "        # Load the trimmed dataset\n",
    "        dataset_dict = load_dataset()\n",
    "        print(\"Dataset loaded.\")\n",
    "    else:\n",
    "        print(\"Loading dataset...\")\n",
    "        dataset_dict = load_and_process_dataset()\n",
    "        print(\"Dataset loaded.\")\n",
    "    \n",
    "        # Save the trimmed dataset\n",
    "        os.makedirs(DATASET_FOLDER_TRIMMED, exist_ok=True)\n",
    "        create_dataset(dataset_dict)\n",
    "\n",
    "        print(\"Trimmed dataset saved.\")\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new DATASET FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:00<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 22.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed dataset saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = load_or_create_trimmed_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimmed tracks check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys in dataset_dict: 50\n",
      "First track folder: AM Contra - Heart Peripheral\n",
      "Contents of the first track folder:\n",
      " - mixture: torch.Size([2, 1323000])\n",
      " - drums: torch.Size([2, 1323000])\n",
      " - bass: torch.Size([2, 1323000])\n",
      " - vocals: torch.Size([2, 1323000])\n",
      " - other: torch.Size([2, 1323000])\n",
      " - new_mixture: torch.Size([2, 1323000])\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of keys in dataset_dict:\", len(dataset_dict))\n",
    "\n",
    "# Check the first track folder and its contents\n",
    "first_track_folder = list(dataset_dict.keys())[0]\n",
    "print(\"First track folder:\", first_track_folder)\n",
    "print(\"Contents of the first track folder:\")\n",
    "def print_stem_shapes(first_track_folder):\n",
    "    for stem_name in dataset_dict[first_track_folder].keys():\n",
    "        print(f\" - {stem_name}: {dataset_dict[first_track_folder][stem_name].shape}\")\n",
    "\n",
    "print_stem_shapes(first_track_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to separate the sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_sources(\n",
    "    model,\n",
    "    mix,\n",
    "    sample_rate=sample_rate,\n",
    "    overlap=0.0,  # set to 0.0 to avoid chunk repetition\n",
    "    device=None,\n",
    "    normalize=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Separate sources from a mixture using the provided model.\n",
    "    Args:\n",
    "        model: The separation model.\n",
    "        mix: The input mixture tensor (batch, channels, length).\n",
    "        sample_rate: Sample rate of the audio.\n",
    "        overlap: Overlap between segments in seconds.\n",
    "        device: Device to run the model on (CPU or GPU).\n",
    "        normalize: Whether to normalize the input mixture.\n",
    "    Returns:\n",
    "        final: The separated sources tensor (batch, sources[drums, bass, other, vocel], channels, length). #CORRECT ORDER UPDATED\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = mix.device\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "\n",
    "    batch, channels, length = mix.shape\n",
    "\n",
    "    # normalize the input by its RMS\n",
    "    if normalize:\n",
    "        # mix = mix / torch.sqrt(torch.mean(mix ** 2, dim=-1, keepdim=True))\n",
    "        mix = mix / torch.max(torch.abs(mix))\n",
    "\n",
    "    # chunk_len for entire 30s, no overlap\n",
    "    chunk_len = int(mix.shape[2] * (1 + overlap))  # effectively 30s if overlap=0\n",
    "    start = 0\n",
    "    end = chunk_len\n",
    "\n",
    "    overlap_frames = int(overlap * sample_rate)\n",
    "    fade = torchaudio.transforms.Fade(fade_in_len=0, fade_out_len=overlap_frames, fade_shape=\"linear\")\n",
    "\n",
    "    # Prepare final buffer\n",
    "    final = torch.zeros(batch, len(model.sources), channels, length, device=device)\n",
    "\n",
    "    while start < length - overlap_frames:\n",
    "        chunk = mix[:, :, start:end]\n",
    "        with torch.no_grad():\n",
    "            out = model(chunk).to(device)\n",
    "            \n",
    "        out = fade(out)\n",
    "        final[:, :, :, start:end] += out\n",
    "\n",
    "        if start == 0:\n",
    "            fade.fade_in_len = overlap_frames\n",
    "            start += chunk_len - overlap_frames\n",
    "        else:\n",
    "            start += chunk_len\n",
    "        end += chunk_len\n",
    "        if end >= length:\n",
    "            fade.fade_out_len = 0\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sdr(original_stem: torch.Tensor, predicted_stem: torch.Tensor, device: torch.device=None):\n",
    "    \"\"\"\n",
    "    Calculate the Scale-Invariant Signal-to-Distortion Ratio (SDR) between the original and predicted stems.\n",
    "\n",
    "    Args:\n",
    "        original_stem (torch.Tensor): The original stem waveform (shape: [channels, samples]).\n",
    "        predicted_stem (torch.Tensor): The predicted stem waveform (shape: [channels, samples]).\n",
    "\n",
    "    Returns:\n",
    "        float: The SDR value.\n",
    "    \"\"\"\n",
    "    # Ensure both tensors are on the same device\n",
    "    original_stem.to(device)\n",
    "    predicted_stem.to(device)\n",
    "    \n",
    "    # Initialize the SDR metric\n",
    "    sdr_metric = ScaleInvariantSignalDistortionRatio().to(device)\n",
    "\n",
    "    # Compute the SDR\n",
    "    sdr_value = sdr_metric(predicted_stem, original_stem).item()\n",
    "\n",
    "    return sdr_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the model in standard usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> `compute_sdrs` </b>\n",
    "This function computes the Scale-Invariant Signal-to-Distortion Ratio (SDR) for each stem. It compares the original stems from `stems_dict` with the predicted stems from `separated_sources` using the `evaluate_sdr` function. The SDR values are stored in a dictionary (`sdr_results`) with stem names as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sdrs(model, device, stems_dict, separated_sources):\n",
    "    \"\"\"Compute SDRs for each stem.\"\"\"\n",
    "    sdr_results = {stem: [] for stem in model.sources}\n",
    "    for i, stem_name in enumerate(model.sources):\n",
    "        # test normalization\n",
    "        original_stem = stems_dict[stem_name].to(device)\n",
    "        predicted_stem = separated_sources[0, i].to(device)\n",
    "        sdr_value = evaluate_sdr(original_stem, predicted_stem, device=device)\n",
    "        sdr_results[stem_name].append(sdr_value)\n",
    "\n",
    "    return sdr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta_sdrs(model, device, stems_dict, separated_sources, target_stem, beta):\n",
    "    \"\"\"Compute SDRs for each stem.\"\"\"\n",
    "    sdr_results_beta = {stem: [] for stem in model.sources}\n",
    "    for i, stem_name in enumerate(model.sources):\n",
    "        if stem_name != target_stem:\n",
    "            predicted_stem_beta_mod = separated_sources[0, i].to(device) / (1 - beta)\n",
    "        else:\n",
    "            predicted_stem_beta_mod = separated_sources[0, i].to(device)\n",
    "        \n",
    "        original_stem = stems_dict[stem_name].to(device)\n",
    "        sdr_value_beta = evaluate_sdr(original_stem, predicted_stem_beta_mod, device=device)\n",
    "        sdr_results_beta[stem_name].append(sdr_value_beta)\n",
    "\n",
    "    return sdr_results_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sdr_across_dataset(dataset_dict, model, sample_rate, device, normalize, verbose=False):\n",
    "    \"\"\"\n",
    "    Evaluate the SDR for each track in the dataset.\n",
    "    Args:\n",
    "        dataset_dict (dict): Dictionary containing the dataset.\n",
    "        model: The separation model.\n",
    "        sample_rate: Sample rate of the audio.\n",
    "        device: Device to run the model on (CPU or GPU).\n",
    "        normalize: Whether to normalize the input mixture.\n",
    "        verbose (bool): Whether to print detailed logs.\n",
    "    Returns:\n",
    "        average_sdr (dict): Dictionary containing the average SDR for each stem.\n",
    "    \"\"\"\n",
    "    sdr_results = {stem: [] for stem in [\"bass\", \"drums\", \"vocals\", \"other\"]}\n",
    "\n",
    "    sdr_results_list = []\n",
    "\n",
    "    for track_name, stems_dict in tqdm(dataset_dict.items()):\n",
    "        if verbose:\n",
    "            print(f\"Processing track: {track_name}\")\n",
    "\n",
    "        # Ensure the mixture exists in the stems\n",
    "        if \"new_mixture\" not in stems_dict:\n",
    "            if verbose:\n",
    "                print(f\"Skipping track {track_name} as it does not contain a new mixture.\")\n",
    "            continue\n",
    "\n",
    "        # Load the mixture and move it to the correct device\n",
    "        mixture = stems_dict[\"new_mixture\"].to(device).unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        # Perform source separation\n",
    "        separated_sources = separate_sources(model, mixture, sample_rate=sample_rate, device=device, normalize=normalize)\n",
    "\n",
    "        # Evaluate SDR for each stem\n",
    "        sdr_results = compute_sdrs(model, device, stems_dict, separated_sources)\n",
    "\n",
    "        # Convert sdr_results to a tensor for this track\n",
    "        sdr_tensor = torch.tensor([sdr_results[stem][0] for stem in model.sources])\n",
    "        \n",
    "        # Append the SDR tensor to the collection\n",
    "        sdr_results_list.append(sdr_tensor)\n",
    "\n",
    "    # Calculate the average and standard deviation SDR for each stem\n",
    "    if sdr_results_list:\n",
    "        sdr_collection = torch.stack(sdr_results_list)\n",
    "        average_sdr = {stem: torch.mean(sdr_collection[:, i]).item() for i, stem in enumerate(model.sources)}\n",
    "        std_sdr = {stem: torch.std(sdr_collection[:, i]).item() for i, stem in enumerate(model.sources)}\n",
    "    else:\n",
    "        average_sdr = {stem: None for stem in model.sources}\n",
    "        std_sdr = {stem: None for stem in model.sources}\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nAverage SDR for each stem:\")\n",
    "        for stem, avg_sdr in average_sdr.items():\n",
    "            print(f\"{stem}: {avg_sdr:.2f} dB\" if avg_sdr is not None else f\"{stem}: No data\")\n",
    "        print(\"\\nStandard Deviation of SDR for each stem:\")\n",
    "        for stem, std in std_sdr.items():\n",
    "            print(f\"{stem}: {std:.2f} dB\" if std is not None else f\"{stem}: No data\")\n",
    "\n",
    "    return sdr_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:33<00:00,  1.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SDR across the dataset using the provided function using no normalization.\n",
    "sdr_collection = evaluate_sdr_across_dataset(dataset_dict, model, sample_rate, device, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sdr_results(sdr_collection, model):\n",
    "    \"\"\"\n",
    "    Create a box plot for the SDR results for each stem using raw data.\n",
    "\n",
    "    Args:\n",
    "        sdr_collection (torch.Tensor): Tensor containing all SDR results [n_samples, n_stems].\n",
    "        model: Model object containing the sources list.\n",
    "    \"\"\"\n",
    "    stems = model.sources\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.rcParams.update({'font.size': 16})  # Sets default font size for all elements\n",
    "    \n",
    "    # Extract data for each stem\n",
    "    box_data = [sdr_collection[:, i].numpy() for i in range(len(stems))]\n",
    "    \n",
    "    box_plot = plt.boxplot(box_data, labels=stems, patch_artist=True, showfliers=False, orientation=\"horizontal\", notch=True)\n",
    "    \n",
    "    # Color the boxes\n",
    "    colors = ['blue', 'orange', 'green', 'red']\n",
    "    for patch, color in zip(box_plot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    plt.xlabel('SDR (dB)')\n",
    "    plt.ylabel('Stem')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b3/9p1vx9h57c39zzmtx2ds2ffw0000gn/T/ipykernel_84019/3312871678.py:18: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  box_plot = plt.boxplot(box_data, labels=stems, patch_artist=True, showfliers=False, orientation=\"horizontal\", notch=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4UAAAIZCAYAAAARA5osAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWv5JREFUeJzt3Qd0VGX+xvEnvZNCCKF3DCpIF+lFepEqiCjY0HUti65dV11ddVdX17Ugq9hhBelNpQSQKh1EioD0FiCUQOjJ/7zvOvknkED6THK/n3PumWHmzsw7cLkzz/ze4pWampoqAAAAAIAjebu7AQAAAAAA9yEUAgAAAICDEQoBAAAAwMEIhQAAAADgYIRCAAAAAHAwQiEAAAAAOBihEAAAAAAcjFAIAAAAAA7m6+4GIP+kpKRo3759CgsLk5eXl7ubAwAAAMBNUlNTlZSUpLJly8rb+8q1QEJhMWICYYUKFdzdDAAAAAAeYvfu3SpfvvwV9yEUFiOmQuj6hy9RooRbKpWHDh1SqVKlrvprBJAbHGMoaBxjKAwcZyhoHGMwTpw4YQtGroxwJYTCYsTVZdQEQneFwjNnztjX5gSEgsAxhoLGMYbCwHGGgsYxhvSyM6yMowQAAAAAHIxQCAAAAAAORigEAAAAAAcjFAIAAACAgxEKAQAAAMDBCIUAAAAA4GCEQgAAAABwMEIhAAAAADgYoRAAAAAAHIxQCAAAAAAORigEAAAAAAcjFAIAAACAgxEKAQAAAMDBCIUAAAAA4GCEQgAAAABwMEIhAAAAADgYoRAAAAAAHIxQCAAAAAAORigEAAAAAAcjFAIAAACAgxEKAQAAAMDBCIUAAAAA4GCEQgAAAABwMEIhAAAAADgYoRAAAAAAHIxQCAAAAAAORigEAAAAAAfzdXcDAAAF48SJEzpw4ICcKDo6WlFRUSruTp8+rd27d2d7fx8fH1WtWlVeXl4F2i4AQNFCKASAYuqphx/WnnXr5EQ+YWFq3q2bbunVSzVq1FBxk5CQoKlTpmjm+PFKzknw9/PTI3/7m9q3b1+QzQMAFDGEQgAopg7t26feqalqU7KknCRV0roTJzR15EjN//Zb1WreXD379VOTJk3k7V10R02kpqZq48aNmjxxopbMmKGQI0fUJTBQzaKi5JvNyt8Le/faQAkAQHqEQgAoxkr6+alycLCcpkpwsLqXLq2fjh3T5O++0+tz5ijmuuvUvX9/WyULCQlRUXHhwgUtXLhQU8aN05YlS1Tu5Ek9EB6utlWrKtDHJ0fP5VuEQzEAoOAQCgEAxZK3l5duioy029ZTpzRl3Tp9vmaNRn34odr36aPuPXqoTJky8lRJSUn6/vvvNW3MGCVu3qy658/rxVKl1KBMGcYEAgDyFaEQAFDsVQ8J0WNVq2rIuXOanpCg795+W9O++EKNO3ZUzz59dN1113lM0DITx0yZPFnxEycqdd8+tfbx0S2lS6uSAyu+AIDCQSgEADhGlL+/7ihfXrdevKh5R45o8ujRembKFFVt1Ei33HqrmjVr5rbxgmvWrNHkCRO0ctYsRRw9qn4hIepcqZLC/fzc0iYAgHMQCgEAjhPg46OOMTHqUKqUVp84oSnz5+udhQv1Wc2aatahg/r376/IyMgCb8e5c+c0d+5cTR4zRrtXr1bV5GQNi4pSi+rV5cf4PwBAISEUAgAcy3QZrR8ebrfdp09r8q+/6ruff9YPY8aoTc+euqVnT1WqVCnfXzcxMVHTp0/Xd2PH6uRvv6lxaqoeLFVK15Ur5zHdWAEAzkEoBABAUoWgIP2xcmX1T05W/LFjmvHhh5o1erTqtm2rW/r0UYMGDfIc2LZt26bJkyZpwZQp8j14UO39/dW9bFmVCQzMt/cBAEBOEQoBAEgnzNdXt5Ytqz6pqVqYmGjH+b383XcqV7euetx6q9q2bavAHIS4lJQU/fTTT5o8bpx++fFHxZw4ocElSqh9lSoK8eVjGADgfnwaAQCQxZp+raOj1apkSW08eVKTly3TR8uW6auqVdWpXz917dpV0dHRWT4+OTlZs2bN0tSxY3Vw/XrVOntWz5QsqRtr1JAPXUQBAB6EUAgAwBWYLqPXhoXZ7eDZs5q2e7dmvP66Jn7yiZp166ZbevVSzZo10/Y/ePCgpk6Zopnjxunc7t1q7uWlp2JiVCM01K3vAwCArBAKAQ9gKgqbNm1SXFycglmLDPBYpQMCdE/Firrt4kXNPnRIUz/9VI+PG6dazZurbceOWrVihZbOmKHQI0fULThYXSpUULS/v7ubDXgcPvcAz0IoBDyA+WA0k1isXLlS9evXd3dzAFxFsI+PesTGqlvp0lp27Jgmf/edRs+foVurJOkm3zJqWq2aXfYCQOb43AM8C6EQAIBc8vbyUpPISLsl+iYqqvYBaUOYdJpACAAoOlgZFwCAfBDl5+fuJgAAkCuEQgAAAABwMEIhAAAAADgYoRAAAAAAHIxQWAjmzZtn17lq3bq1u5sCAAAAABkQCgEAAADAwQiFAAAAAOBghEIAAAAAcDCPC4WbNm2y4+8iIyN15syZLPdr2LCh3W/y5MlptyUmJurZZ5/Vddddp+DgYIWFhalBgwb6xz/+odOnT2f5XHv37tUTTzyh2rVr28eEhISoZs2aGjJkiBYvXpxh32XLlunJJ59U48aNFRsbK39/f5UuXVrdu3fX7Nmzc/x+V65cqf79+6t8+fL2uUqUKKGqVauqT58+Gd4bAAAAABQEX3mYuLg43XTTTVqyZIkmTZqkAQMGXLbPzz//bMOUCWNdu3a1t/32229q27atdu7cqVKlSqlLly46f/685s6dq6eeekpjxoyxoc2EzfTmzJmjvn376tixY4qJiVG7du1sONuxY4dGjx5t92natGna/iZ0muc0wdMEThMgt23bpmnTptntX//6lx599NFsvVfz2p07d7btvOGGG+z7vnjxog2p06dPt9dvueWWPP6NAgAAAEARCoXG3XffbUPh559/nmko/Oyzz+zloEGD5Ov7v7cwcOBAGwh79Ohhw5wJa8ahQ4fUqVMnrVq1Sg899JBGjRqV9jy7d++2Fbnjx4/r6aef1ssvv2wDoUtCQoJ+/fXXDK/9+OOP66uvvlKZMmUy3G7aa17HVBxNyCxXrtxV3+ff/vY3Gwi//vpr3X777RnuM23auHHjFR9/9uxZu7mcOHHiqq8Jz+SqZF/t39zpUlJSbI+AqKgoeXt7XEcHj3P0xAltO3VKyRcvKtjHx93NgQe4kJKi7du3289EuA/nsv//vLtSTy4AhccrNTU1VR4mKSnJds003Ud37dqVIWCZEGX+bMLe+vXrbcVu4cKFatGihe0yaiqGpoKYnqkqmu6m5sRrgqPpqmkMGzbMVvZM188pU6bkud2mivj666/rgw8+0IMPPphhSYo2bdqoVatW9rqLafuGDRvsB8OlFczseOmll2yQvZQJlKYbqjs+5EyQNhVXp37I5Zb5scL8yAEUhJUtWqh+eLi7m1EkmI/Es+fOKcDf3w5RyJGgJOna1dKGetLpMHmiHuvXa+qOHe5uBpAmsx/GkXd8J4OrYBQeHp6tbOCRlUIzrs9U27788ku7PfPMM2n3mW6VJhCaMX0mVBmuoGUqdZcGQsN08zTdM9euXav58+ennXy+//57ezl06NActe/IkSO2HSaUHj161AZVY8uWLfZy8+bN2Xoe8x5MKDTtMYGySZMmaZXP7DB/L4899liGf/gKFSrk6L3AM1SuXDntw7FWrVrubo7H4tf1nHniD39Qt6QkxYWGursp8BDhAQF65ZVX7BALuA/nsv9VCs2Poa7PPwDu5ZGh0NWF1ARC04U0fSh0dR2966670m4zY/CMKlWqZPl81apVs6HQta9hqoaucYzZ9fHHH9sK46lTp7LcJ7vdOE1Vcd26dfruu+/sFhQUpPr169tF7k1QvFo4CAgIsBuKPvNvb5h/c3MMIHP88pkzkSVKqFpKCl1HkcbX29t+VnKecS/OZZd//gFwL489E7Vs2dIGOTOmzzUDqDmBzpgxQ4GBgZmONSxophvq/fffb8fx/f3vf7dVvpMnT9qTu+lyNGLECLtfdnvkmi6yK1assBPXPPfcc7rxxhvtOA8z1tBUQc1rAAAAAIAjQ6EZy2GWhEhfHTRd6y5cuKDevXsrIiIibV/XmEMznjArrvvSj0+sWLFi2jIY2fHtt9/awPfwww/bZSlMVcdMaOMad+LqPprT92kqg6+++qoNh6Y7yfDhw+3tpkupmdkUAAAAABwXCg0TCk23irFjxyo5OTnTrqOGCVWuMYIHDx687HlWr16tNWvW2OcyFUgXMwbR1SU0O0xgMypVqnTZfWZSnPHjxyuvTBX0gQceUJ06dWwF0nQvBQAAAABHhkIzS2j79u3tGD1TNTMTu5jqnlmPML3mzZvbrpdmWmPTvdMESJfDhw/b2wzT5TT9RCxmkhYzqY2ZefT5559PmzDGxXRXNTOburjG+H3xxRd2htT0gdDMNmqm+c6Jt956y86ueilTuXRVHTMLoAAAAADgiFCYvir47rvvZqgeXsqsTWgC1OTJk+0g+n79+qlnz552XOLy5cvtoPr3338/w2NMwBw3bpwNhmYcnwmMvXr10q233mpDpgmln3zySYa2mNcwlUfzGmZfM0uquc08T3YXrXcxXUbNY03YNF1izeQyZumK2rVr24ls7rzzTiYDAAAAAODsUGiCnZmy+dJxhpeqWrWqnaTFzFRasmRJTZs2TbNmzbKh8I033rAVv8zWAuzQoYOtQJpAZ8Ypmi6oZibQY8eO6Y477rBdOV3M/WZiGFMVNNfNfmbRevMc5rXr1q2bo/dm1jM0QdMsQ2GWyjDdT0210VRHJ06caGdeBQAAAABHLknhYpZcMOsCZocJj6+99prdcsJUDM0i9tkRHR1tw1xmqlevnmloNWMeM5uR1FQGWbAVAAAAgDt5fKUQAAAAAFBwCIUAAAAA4GCEQgAA8sgMEdh75oy7mwEAQPEcUwgAgKc6n5KiHxMTNSUxUUdL+Kj3zyHyO3BMrUoEKdSXj1gAQNHAJxbgAeLi4rRy5Up7CcDzHT9/Xt8lJGj6qVM6Fhmphv37q2/79lq1cqXmTZqkz7ZvVzs/P/UoXVrlgoLc3VzA4/C5B3gWQiHgAYKDg1mTEigCdiQna8rBg5p38aK8ypbVzffeq+49eth1bY0WLVpo8JAhdsmi6WPGaMbWrWp08aJuiYlRnbAwu7QSAD73AE9DKAQA4CrjBVccP64phw5pjZ+fStaqpYH9+6tjx44KCwu7bH+zju1tt92mPn36aMGCBZo0ZoyeX7FClQ8cUI/ISLUqWVL+3gzpBwB4DkIhAACZOHPxouIPH9aU48e1NyxMNW6+WU/cequaNm0q32yMF/T391e7du3Utm1b/fzzz5o8YYLe++EHfbF1qzoHB6tLTIwi/f0L5b0AAHAlhEIAANI5fO6cZick6IczZ3SqZEk1GzJEj/bsacc+5ab7p3lMnTp17LZv6FBNnTJFkyZM0Ljdu9XK21s9YmJUNSSkQN4LAADZQSgEAEDS5pMnNfngQc2/cEEhVauqU79+6ta9u2JiYvLtNcqWLav7H3hAg+64QzNnztTUMWM0Z8MG1d63T7dER6tRRIS8GXcIAChkhEIAgGNdTE3VkqNHNfnIEW0KDFRs/frq36GDHQ8YUoDVO/PcvXr1Uo8ePbRkyRJN/vZbvbpokcps2aLu4eFqHx2tQB+fAnt9AADSIxQCABzn1IULmnnokKYmJelQeLhqd++u5/v2VYMGDXT48GEFFdIyEj4+PmrevLndNm/erCmTJumTadM06rff1CEgQN1Kl1ZMQEChtAUA4FyEQgCAY+w7c0ZTDx7U7HPndCE2Vq1uv109brlFVatWtfenpKS4rW3XXHONnnjqKd11zz2aPn26vh87VpO2b1dTyS5pERcaypIWAIACQSgEABT7JSV+TkrS5IQELffxUYnq1dWzXz916dJFkZGR8jTR0dEaPHiw+vfvr/j4eE0ZO1ZPrlmjGvv3q2fJkmoaGSlflrQAAOQjQiEAoFg6n5KiHxMTNTkxUdtDQlS5RQs93K+fWrVqZZeL8HSBgYE2uHbu3FkrV67U5PHj9WZ8vEpu3apuoaHqGBOjsGwsjQEAwNXwaQIAxdiBs2e1ISlJTpIqad2JE5p+8qSOR0Wp0YABuqd3b7skRFHsfmna3LBhQ7vt3LlTkydN0uhJk/Tf7dvVzs9PzaOi5JvN92WCMgAAlyIUAkAxVbZSJU09elRTT56U0wRERandvffa8YLlypVTcVGpUiU98uijGjxkiL777jtNHzNG3+3enf0niIy0y2IAAJAeoRAAiqk3/v1vHT16VE4UERFRoEtKuFt4eLgGDBhgl85ISEjI9uO8vb1VpkyZAm0bAKDoIRQCQDEVHBxsNxRffn5+xaoSCgBwD6YvAwAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBgvu5uAABcyblz5zR8+HAdSTyi1NRUnTp1SiEhIfLy8nJ30xQRHqFbb71V5cuXV1Fi/h7nz5+vefPmKSU1Jd+fPygwSA8++KDCw8Pz/bkBAED+IxQC8Gi//vqrPhv/mZJLJsvb31sXL1yUj6+PPEHKkRRN+G6CBtwyQAMHDlRUVJQ8PQyuXr1aIz4ZoSXrl+hM1Bl5B+R/h5HU3amqX7++OnbsmO/PDQAA8h+hEECRUKl9JQVEBOjc2XPyD/D3iEphyoUUJaxJ0Hvj3tPE7yZqyIAh6t27t61kepqtW7fq45Efa/aS2ToVfkqxPWIVVi6sQF5ry/tbCuR5AQBAwSAUAkAueft6K7ZhrKKvj9aBZQf02sev6dvJ3+qeO+5Rly5d5Ofn5+4mav/+/friyy808YeJOuZ/TKXalVKZamU8IlQDAADPQCgEgDzyDfRV+Zblda7eOf22+Dc98+YzGjN+jIbePVStWrVySwA7fvy4/vvf/2r0xNE6eOGgIptEqsZ1NeTlTRgEAAAZEQoBIJ/4h/mrSscqOt3wtNYsWKNH/vKImtZuqvvvvV9169YtlHB45swZTZo0SZ+O/lS7TuxSSN0QVatfTT5+njEOEwAAeB5CIQDks6CSQarWs5qS9iZp3oJ5Wj5sudo3ba97775X1atXL5DXvHDhgmbOnKlPvvhEG/dtlH8tf1XpWUW+QZzmAQDAlfFtAQAKiJnIJbR/qI5tO6aJiyZq7tK56t2pt+68406VKVMm32YUXbx4sUaMHKFVW1YptVKqKtxeQQHhAfny/AAAoPgjFAJAATJdRiOrRyqiaoQOrz+sT3/4VDPiZ2hgr4EaMGBAntby+/nnn/Wfkf/RglULdDbmrMr2LavgmOB8bT8AACj+CIUAUAjMBC+l6pRSVK0oHVx1UG+Pflvjp4/X3QPvVs+ePRUYGJjt59qxY4dGfjpS3/34nZJCkxTbNVYlKpYo0PYDAIDii1AIAIXITPhS9sayulDngvYt3aeXP3hZYyeO1b2D71WHDh3k65v1afnQoUP6+uuvNXb6WCV6Jyq6VbRir4lleQkAAJAnhEIAcAMzAUzFNhV1tv5ZbV64WU++/mTaMhZNmzbNEPSSkpI0duxYfT3ua+09s1cRjSJUvU51eft4u/U9AACA4oFQCABuZCaEqdq1qpITkrVswTKtfWatWtRvYZexqFmzpqZMmaLPRn2mbUe2KfiGYFVvWF0+/iwvAQAA8g+hEAUiOTlZmzZtUlxcnIKDmfgCuBozQUz1PtV1YtcJzVwwU0seXqIykWW07dA2+db0VeWuleUX4ufuZgJXxfkfAIoe+h6hQJgvBA0aNLCXALLPTBhTY2ANlW3prc4V1qj2raVU6eZKBEIUGZz/AaDoIRQCgIcx4wmrVg7Wg5EnVCaUSWQAAEDBIhQCAAAAgIMRCgEAAADAwQiFAAAAAOBghMIsDBkyxI7r+fzzz93dFAAAAAAoMI4MhfPmzbOBr3Xr1u5uCgAAAAC4lSNDIQAAAADgfwiFAAAAAOBgxSYU7tmzRw8//LBq1KihwMBAhYeHq1mzZhoxYoQuXryYtp/pMtqmTRt7ff78+bYbqWurXLlyps+9fft23XHHHYqNjVVAQICqVaum559/XmfPns2yPStXrtTtt9+uihUr2sdERUWpY8eOmjFjRqb7m9c2bdixY4cmT56stm3b2seY20x3VwAAAAAoCL4qBpYvX65OnTopMTHRhrCePXvq+PHjNkwtXrxYEydO1JQpU+Tv72/3M6Hxhx9+UOnSpe2fXaKjoy977jVr1ujRRx9VZGSkWrVqZV9j0aJF+tvf/qZffvnFPvel3n33XT322GNKSUlR3bp1deONN+rAgQO2PTNnztTLL7+sv/zlL5m+l3/+8596//331bBhQ9u2ffv2ycfHJ5//xgAAAACgmIRCU63r16+fDWsPPPCA/v3vf8vPz8/e99tvv6ldu3Y2AJogZoLc008/rSZNmtjb4uLirjq7qAl4zz33nH28K5ytX7/ePsekSZO0ZMkS3XTTTWn7m+cdNmyYSpYsqfHjx6tly5Zp9/3888/q0qWLXnzxRRswzXap4cOH20phjx498vFvCQAAAACKaSj89ttvtXPnTpUtW1b/+te/0gKhUbVqVb311lvq27ev3nvvPb3wwgu2SpgTDRo00CuvvGK7cbpcf/31tjvpRx99pNmzZ2cIhSbwpaam2vvSB0Kjdu3aevvtt3Xrrbfa9mQWCgcPHpztQGgCcfourCdOnJCnOH36tL3cuHGju5uCIm7r1q1KPpmsi+f+vxs4PFvKxRRt2bJFpUqVUlFjeniYHxlN931v72IzwqJQuc77rs8BAIDnK/Kh0DXebsCAAXbs3qV69+5tu34ePXrUjvMz4wxzolu3bhkCoUutWrXs5d69e9NuO3z4sJYtW6agoCB179490+dzLYNhurVmxgTY7Hr99ddtBdMTmbGRxqBBg9zdFBQTkR0iFRwT7O5mIBvOnT5nx3jD2cznQE4/cwEA7lHkQ6ErlFWpUiXT+02gM/eZUJg+wGWXGaOYmRIlStjLM2fOZJiQxlQJza+jmQXU9A4dOpTp7VlNdpOZZ555xo5dTF8prFChgjyB6318/fXXaQEayG2l8Pk3nldIbIi7m4Js8g/yt70hmjZtqqKGSmH+VArND4I5+TwDALhXkQ+FBS0nXwrMlwkjNDRUffr0ydXrmSpjdpngebXw6S6u92ECYf369d3dHBRhZoKo4NBg+fgz4VJR4e3jbWeCLor/9815PCEhQTExMYTCPMrJ5xkAwL2KfCgsV65c2qQyWTEVvPT7FhRXlc5UJz/99FO+UAAAAADweEU+tbjG6I0ZMyZDV04Xs2SE6ToaFhZmJ41xVR6MCxcu5GtbzGQ3derUUVJSkr7//vt8fW4AAAAAKAhFPhSa5SjMuD+znp8ZX5c+6JkK4eOPP26vm0kPXDOPli9f3l6a2fHOnz+fr+159dVX7eVdd92lqVOnXna/GXP4008/2fUKAQAAAMDdinz3UTOmbty4cXahd7PG34wZM+wagqZaFx8fb6uHHTt2tEtFuJgQaRaHX7FihV0mwlw3gdEsXv/GG2/kqT1m1lGztqEJo2ZpierVq+uaa65ReHi4nVxm7dq1drzKU089pQ4dOuTD3wAAAAAAOLhSaDRq1Ehr1qzRH//4R7vAvOkyumDBAtWrV88GxWnTpqV1GXUxC8sPHDjQzthpup6OHDlS33zzTb6055FHHtHq1as1dOhQO75wzpw5dqH7bdu22Tb9+9//tvsAAAAAgLsV+Uph+kle3n///Wzvb6qFo0aNyvL+zz//3G5ZGTJkiN2yYha4HzFiRI7X9QMAAACAwlQsKoUAAAAAgNwhFAIAAACAgxEKAQAAAMDBCIUA4GFSU1KV+OtRe/30kcvXXwUAAMhPxWaiGQAo6sw6pse2HtOhxYdUXaH6tkY1/brghBLKJKlc83IKCA9wdxMBAEAxRChEgYiLi9PKlSvtJYCrS9qTpAMLDyjkeIj6NO+je+++186SHDZ7tj7+/GNtHLVRfrX8VObGMvIL9nN3c4Escf4HgKKHUIgCERwcrPr167u7GYDHO33ktPYt2Ce//X5qU6eN7n/5ftWtWzft/k6dOql169aaPHmyPhv9mbZ/uV2hdUNVukFp+fj5uLXtQGY4/wNA0UMoBAA3OHfinPYu3qvUbamqV62e7n/1frVo0UJeXl6X7RsYGKj+/fvbgDhmzBiNmjBK29ZvU0SjCJWqXUpe3pc/BgAAILsIhQBQiC6cuaD9y/br7C9nVbN0Td371L3q3LmzfH2vfjoODw/X0KFD1aNHD3351Zca/914bVmzRaWallJE9YhMAyUAAMDVEAoBoBCkXEjRwdUHlbQqSRVCK+iu++9Sr169bFe7nIqNjdWTTzypPr376JNPP9HM+Jk6vPKwYlvEKqxcWIG0HwAAFF+EQgAo4OUljmw8osSliSrlVUp39btLt912m6KiovL83NWqVdPrf3td/df014hPRmjxlMVKKJOgsi3KKqhkUL60HwAAFH+EQgAooOUljm8/roRFCQo/Ha4729+pIYOHqFy5cvn+WmZimg/f+1ALFizQiJEjtOabNfKq5qVyzcrJP8w/318PAAAUL4RCAMhnJ/ef1P4F+xWcGKzuN3bXfffcp2uuuaZAX9OMJ2zZsqVuuukmff/99/rky0/069e/KuC6AJVpXEa+gZzuAQBA5viWAAD55MzRM9q7cK98dvuoxXUtNPTZoWrYsGGhTgDj5+en7t27q127dpowYYI+/+Zz/bbpN5WoV0Ix9WLk7etdaG0BAABFA6EQAPLo/KnzdnmJlC0pql2ptoa+NFRt2rSRt7f7ApiZwGbQoEHq0qWLRo8erW8mf6Mt67aoZJOSKlmrJMtYAACANIRCAMili+cu6sDyA0pel6xqJavpnmH3qFu3bvL395xxfGZCm4ceesjOdPr5F59r8qzJ2rJqi2KaxSi8SjjLWAAAAEIhgCLAS9r5/U7b9fHChQvZWtOvMKQeTVXZwLJ6+K6H1a9fP4WGhspTmQlunnv2OfXt01f/+eQ/mjtzrg6GHJR3YP5XM73MPxgAACgyPOObFQBkIS4uTg/f+bASExPtjJ4nT5604csTKlxmMfnevXsrOjpaRYWZ8Oatf7ylFStWaN68eQXyGgEBAWrWrFmBPDcAAMh/hEIAHs1UBe+55x57PSUlRQkJCYqJiXHreL2izgTqRo0a2Q0AAIBvVQAAAADgYIRCAAAAAHAwQiEAAAAAOBihEAAAAAAcjFAIAAAAAA6WL7OP7tmzR/v27dOZM2ey3Kdly5b58VIAAAAAAE8Jhd9++62ef/55bd269arTn5sFpwEAAAAAxSQUjh07VrfddptdTDoqKkqVK1dWWFhY/rYOAAAAAOCZofC1116zl++++64efPBB+fj45Ge7AAAAAACeHAo3b96sm266SQ8//HD+tggAAAAA4Pmzj0ZERKhSpUr52xoAAAAAQNEIhW3atNHq1avztzUAAAAAgKIRCv/yl79o7969euONN/K3RQAAAAAAzx9TGBcXp5kzZ2rAgAGaPHmyOnfurIoVK8rbO/Oceeedd+alnQAAAAAAT1uncPHixUpMTNSuXbu0bNmyK+5LKAQAAACAYhQKP/30Uz3++OP2ep06dVSjRg2FhobmZ9sAAAAAAJ4aCt955x35+vpqwoQJ6tatW/62CgAAAADg2RPNbNu2TS1btiQQAgAAAIATQ2FkZKRKlSqVv60BAAAAABSNUGhmG126dKlSUlLyt0UAAAAAAM8Pha+88orOnj2rRx55ROfOncvfVgEAAAAAPHuimY8//thWC4cPH67p06erTZs2Wa5T6OXlpRdeeCGvbQUAAAAA5DOv1NTU1Nw80IQ/E/au9HDX/eby4sWLeWknsuHEiRMKDw/X8ePHVaJEiUJ/fdOVOCEhQTExMZn+OADkFccYChrHGAoDxxkKGscYcpoNcl0p/Mtf/mLDHgAAAACg6Mp1KHzppZfytyUAAAAAgEJHPRkAAAAAHCzXlcL0TD/V5cuX69ChQ6pUqZKaNm2aH08LAAAAAPDkSmFSUpLuvfdeO4i1Y8eOGjRokD755JO0+831smXL6qeffsqPtgIAAAAAPCUUnj59Wq1bt9ann36qyMhIuzzFpTORduvWTQcPHtSkSZPyo60AAAAAAE8JhW+//bZWr16t2267Tdu2bdO0adMu2yc2Nla1atXS3Llz89pOAAAAAIAnhcIxY8bY0Ddy5EiFhIRkuV/NmjW1Z8+e3L4MAAAAAMATQ6GpDjZu3FiBgYFX3C84OFiHDx/O7csAAAAAADwxFPr4+Oj8+fNX3c9UCa9USQQAAAAAFMFQWK1aNa1du1YXLlzIcp+TJ09q3bp1dlwhAAAAAKAYhcIePXpo//79evXVV7Pcx9xn1jDs1atXbl8GAAAAAOCJoXDYsGEqV66cXnnlFfXs2VOjR4+2t5slKCZMmKABAwbozTffVOXKlfXAAw/kZ5sBAAAAAPnEN7cPjIiI0Pfff28rhlOmTNHUqVPl5eVlbzObWbOwUqVK9nbGFAIAAABAMQuFxrXXXqv169fr888/14wZM/Tbb78pJSVFFSpUsIvZDx061M4+CgAAAAAohqHQMEtSmO6hdBEFAAAAAAeNKfzyyy+1ePHiq+63dOlSuy8AAAAAoBiFwiFDhuiTTz656n4jR47UXXfdlduXAQAAAAB4YijMLjPhDAAAAADAoaEwISGByWYAAAAAoDhMNPPjjz9m+POBAwcuu83lwoUL+uWXXzRz5kzVrl07b60EAAAAALg/FLZu3dquRejyww8/2O1q3Uf/8Ic/5L6FAAAAAADPCIUtW7ZMC4Xz589XTEyM4uLiMt3X399f5cuXV58+fdSlS5f8aS0AAAAAwH2hcN68eWnXvb297QL1n376af62CAAAAADg+YvXz507V7GxsfnbGgAAAABA0Zh9tFWrVrrmmmsyTCzzz3/+Uy1atFCtWrXUvn17qogAAAAAUFxC4YQJE+wYwueee+6y+1JSUtS1a1c9+eSTWrRokTZv3qw5c+bovvvus4vcAwAAAACKeCg03UWPHDmivn37Xnbfxx9/rFmzZtmZRnv06KH333/fBsSgoCB99dVXdlkKAAAAAEARHlP4008/qUyZMqpXr95l940YMcLOSjpgwACNGjUq7fbGjRvbEGmCYYcOHfKv1QAAAACAwq0U7t+/X3Xr1r3s9sOHD2vNmjX2+hNPPJHhvt69e6ty5co2UAIAAAAAinAoNOEvMjLystuXL19uL0uVKpVpaLz22mu1b9++vLYTAAAAAODOUOjj46NDhw5ddvuqVavsZf369TN9XEREhJ2ZFAAAAABQhENhpUqVbAA8d+5chtvNLKNmPOGNN96YZYWxdOnSeW8pAAAAAMB9obBNmzZ29tEXXnghw4yk8+fPt9fNkhSZWb16tcqWLZsfbQUAAAAAuCsU/ulPf5K/v7/eeustVahQwXYX7dixo73PVAkbNmx42WOWLFliu5xmVUUEAAAAABSRUFi9enW73ERISIj27t1rZxw1YwVNFfCLL77I9DFmqQqjXbt2+ddiAAAAAEDhr1PoWmKiefPmmjZtmg4ePKiKFSuqZ8+eNihmxqxTaNY1bNu2bX61FwAAAADgrlBoxMTE6O67787Wvg8++GBu2gQAKAaOHz9uf0AsKsykaGFhYe5uhkcxk8vt3LlTqampKkrM5HgBAQHubgYAFN9QCABAdjz2yP1K2LNZRYWPf5jqN2mjuvUa2DHzTg0VJgBu2rRJ8XPmaMHcGTp17IC51d3NypHWnQbo8SeecnczAKDIIBQCAArEoYP7NKCJ1Kx2lDxdSkqqNu48qdlrvtGHs8dq9Bcj1KpdV7Vt1041a9a0Sy8VdwkJCYqPj1f8rOnav2ODooNOqmudYDWOi1CAf7anIHC7L3/Yo0OHEtzdDAAoUgiFAIACUzLcX5Vjg1UUVC0boi43xWjrnhNatH6v5s14VzMmjFS5KrXVtn0XuzRTqVKlVJycPn1aixYtUvzsH/TzqoUKTD2mZtd466GB0apdtUyRDMOhQb5KdncjAKCIIRQCAJBOhVKBGtyphO7sIK377YTiVy/X2I+X6uuRUapdv4Xa3txBzZo1U2BgoIqilJQUrVu3TnNmz9bi+d/p/KkDql3+ooZ1ilTT66so0N/H3U0EABQyQiEAAJnw9vZS3erhdvvD2YtavP6o5qyZrH+9Ok0flSirpq062+6lderUKRIVtd27d9vuoXNnTdOR/VtUrsRp9a8fqjb1yqlUhDPHTwIA/odQCADAVQQF+Khdg2i7JRw9q7mrjyj+xxGKn/6VosvWVJv2Xe2avOXKlZMnSUpK0vz58xU/+3tt+WWZQr1PqOW1fmrbIVo1K5QvEmEWAFDwCIUAAORATGSA+rctq1vbpGrz7lOas3KDZoxaq2+/+kDX1L5RbW/upBYtWrhteYsLFy5oxYoVmjN7llYsma3U04fUsKr0zC2RahRXTX6+RWfSGABA4SAUAgCQC6bKFlcx1G73nU/Rsk3HFL96lka8NVsffxCjxs3aq227m9WgQQP5+voW+DISW7dutctIzJ8zXUlHdqpa9Fnd3SxcLetUVHioX4G+PgCgaCMUAgCQR/5+3mpeO8pux06e1/w1RxS/5iu9OnusSkRXVqt2XdTu5ptVtWrVfO2yeeTIEc2dO1fxs2Zo97Z1igpIUvvrg9S2TylVKiKzvgIA3I9QCABAPooI9dMtzWPttuNAsuas3KF5k9/W1G8/VqUade3yFq1bt1ZUVO7Wbzxz5oyWLl2qObN+0NoVP8rvYqKa1PDSvbdG64ZqsfLxYZwgACBnCIUAABQQs0bjPV0rakinVK3eelzxqxfr6w8W6fMRUarXuLXate+oG2+8UQEBAVftHvrLL7/YZSQWzpuhM8f36bqyF/Rw+wg1va6yQoL4OAcA5B6fIgAAFDBTvWt4TYTdTp2+oAU/Jyp+zXi9uXCygiPLq1mrzrZ76bXXXpuhe+n+/fvtMhLxM6cpYc9mxYaeUu86IWpTr4xio4rmOokAAM9DKATyKDk5WZs2bVJcXJyCgxnDA+DKTFWvU+MYu+0/ckbxqw4qfs6HmjXlC5WuUEttO3RVZGSk5s6ZqY1rFyvY67iax/mqXZto1apUlmUkABQIvs84G6EQyCNzAjWzC65cuVL169d3d3MAFCFlSgbq9vblNfDmVP2yI0nxq9Zq3qhlalPqtGJ8g9WtW7SaXFvNTmQDAAWJ7zPORigEAMDNTPXv+iol7HYu8bj8162VGlSX3LTWIQDAWfjpEQAAD0JVEABQ2PjkAQAAAAAHIxQCAAAAgIMRCgEAAADAwbydMoCfKbwBAAAAwKGhEAAAAACQOUIhAAAAADgYoRAAAAAAHMxxofDjjz9WgwYNFBISooiICHXp0kVLly7NdN8NGzboxRdfVLNmzVSuXDn5+/urZMmSuvnmmzV27NgsX2P27Nnq3r27SpcuLT8/P0VGRqpGjRoaNGiQfvzxxwz7nj17Vm+++aZtU1hYmH2N2NhYNWrUSE8++aQSExPz/e8AAAAAAFx85SCPPfaY/vWvf9mQd8stt+jnn3/Wd999p1mzZtmQ16tXrwz7v/322xo5cqTi4uJUu3ZtGyJ37dqluXPnas6cOTZMmn3S++KLL3TXXXfZ640bN1abNm10+vRp7dmzR998842io6PVsmVLe39KSoq6du1qn6tEiRJq0aKFfY1Dhw5py5YtNiwOHDhQUVFRhfi3BAAAAMBJHBUKP/roI1vFa9u2bdptJniZipwJciYsxsTEpN13xx136Nlnn1XVqlUzPM/mzZtttfCdd97RgAEDbPhzefnll5WamqoFCxaoefPmGR6XkJCgvXv3pv154cKFNhDWq1dP8+fPt5XC9FasWKEKFSpk+X5MldFsLidOnMjx3wnyzoR+Y+PGje5uSrFnfkgx1XPzQ4m3t+M6OhQ5x06c1Na955R85qKCA33c3Rw4xLnzKTpw8KBWrVolT8W5DJ54jLm+x7i+18BZHBUK77///gyB0HjiiSdsldAEsE8++cSGQJdWrVpl+jzXXHONXnjhBft848aNyxAKDx48qPDw8MsCoWECZ/rQafY1TIXw0kBoNGzY8Irv5/XXX7chFO61Y8cOe2m6BwPIaMESqel1UapfM9zdTYFDJBw7qy/GjdIXX45yd1OAIvu9xhRK4CyOCoWDBw/O9PY777zThsJ58+ZlCIXGyZMnbRfT1atX6/Dhwzp37py9ff/+/WlVw/RMQDTPY57z0UcftVXArH6hqV+/vnx8fPTpp5+qZs2a6t27t8qUKZPt9/PMM8/YLrHpK4VXqiyiYFSuXNlefv3116pVq5a7m1Os8et60fKnh+7VrY3OKa5iqLubAgeJiQjQ4Dtv1yOP/v/no6fhXAZPrRSaH7hd32vgLI4KhVWqVLni7WbcX3pTp0613UqPHDmS5XNe2mXzww8/VLdu3fTVV1/ZzVQAzaQxpkJpuqNWrFgxbd9q1arZLqimWvnQQw/ZrVKlSrrpppvsc/Tr189OPJOVgIAAu8G9goKC7KUJhCboo2A/5Ew3bFNx54uU54soEarq5c7SdRSFyt/PW7GRpT36fMy5DJ58jLm+18BZOBOlY8YCupixf/3797eB0Iw5XLt2rY4fP66LFy/a/X744YfLHuMKBqZ6OH36dD3++OO6/vrr7fjC559/3s5AaqpJ6T388MPauXOn/vOf/9jqoqkcmglpzC811157bVpFEgAAAAAKgqNC4fbt2684Jqx8+fIZqoRmoK2ZkfTvf/+76tSpY2cIdf3aYmYHzYqvr69d6uKtt97S4sWLbbdTs7SF6XpqxiGeOnUqw/5m6Yr77rvPzly6bds2W7431UJz/emnn86ndw8AAAAADg+FpjvnlW5v3bp12m2u9QFNd85Lmerg6NGjs/26Jky+9NJLdrmJ5ORk/frrr1fc3yyB8dRTT9nra9asyfbrAAAAAEBOOSoUDh8+3E4Ck54Z07ds2TI79u+ee+5Ju901YYiZXTR9F07TffQvf/mLrQBeygQ+s26hWWfwUqYL6bFjx2z3UFdFMj4+XjNmzND58+cvC53Tpk3LMpQCAAAAQH5x5JIUZgmIcuXKaf369XYBe9cMoLGxsWn7du/eXQ0aNNDKlSvtzKBmeYqQkBD99NNP2rdvn63kmW6l6ZnuoWYcoZk4xix2b8YQ+vn52e6pZqF747nnnlOpUqXs9XXr1mnYsGG2kmgGxJctW9Z2WTVrK5lxhmZpi7/+9a+F/LcEAAAAwEkcFQpNVdCsMThixAgtX77cBrZOnTrZNQebNm162bhAU1U0awGOHz/eLjJvwpvZz/w5KSnpslAYGhqqjz76yC5Eb5awmDVrlg2KJuyZ5SYefPDBDOskmuBpJq8xVUQzRtEERzPjk1lWwowl/OMf/5hhnCMAAAAA5DdHhML0M4Q+8MADdssOE/L+9re/2e1qz+sKkqYaabbsMEtSmAloAAAAAMBdHDWmEAAAAACQEaEQAAAAAByMUAgAgAc5deaiu5sAAHAYR4wpBADAk124mKKVm48rfk2ituy6oJtjS2jr1r1qXCdKzWtHKTSIj2sAQMHhUwbIo7i4OLt0ibkEgOwyk5X9ti9Z8asPa/4v53T8QpiqXtNSt/yhsyIjI/Xr7Fn6cE68/jNzh26s5qW29Uqqfo1w+fh4ubvpAIohvs84G6EQyKPg4GC7ziQAZEfiiXOav/aI5qxJ0s6jQYooXU1t+nZTu3btVLly5bT9WrZsqcTEYXaZo/hZ3+mv41Yr3C9Bra8PVLv60apSJtit7wNA8cL3GWcjFAIAUMDOnU/R0g1HFb/mqFbt8JJvSKyatOirIe1uVr169eTj45Pp46KiotSrVy/17NlT27dvV3x8vObNnqbJK7erctQZtatbQq1uiFJkmH+hvycAQPFBKAQAoIC6h27YcVJzVh3Wos0XlJwaoVo3dNKD/TuqRYsWCgkJyfZzeXl5qWrVqnYbMmSIVq9erfg5s/XFgh/0Wfxu1a+cqnb1otQ4LkL+fswhBwDIGUIhAAD56EDiGcWvOqL4dad08FSIYsrXVo/B3dS2bVuVKVMmz8/v6+urRo0a2e3kQw9rwYIFip/9vf4+ZalCpm1Tizg/ta1fUnEVQ22YBADgagiFAADk0anTF7Ro/VHNWXNMG/b5KiiinJq3G6y27drpuuuuK7BwFhoaqs6dO9tt7969mjt3ruJnTtP3X25WmbD9alsnRG3rRSsmMqBAXh8AUDwQCgEAyIWLF1O1ZqtZRuKIlm5J1XmfKNVt1Ft/HtpRTZo0UUBA4QaxcuXKadCgQbr99tv1888/K37OHI2f951GLdir68tdVNu6EWp2fZSCAzMfvwgAcC5CIQAAObDzQLIdJzj/lzNKPBumCtWaaOAfuqp169YqWbKku5tnq5J16tSx2wN/+IOWLFmi+Nkz9d6s+fro++1qWtPbLm9xQ7US8vameykAgFAIAMBVHT95/vdlJE7otyMBCitZSa17dLPdQ6tVq+axY/cCAwPVpk0bux0+fFjz5s3TnJnTNW/Mz4oKOKg2tYPs8hYVYoLc3VQAgBsRCgEAyMT5CylavumY5qxO1ModXvIKjFGjprdo4M3t1aBBAzvhS1ESHR2tvn37qk+fPtq6davmzJ6tmfEzNH7ZTlUvdU5tb/jf8hYlQvzc3VQAQCErWp9oAAAU8DISv+4+pYW/7NeCjed18mIJ1bz+Zt33WCe7mHxYWJiKOlPVrFGjht3uve8+LV++XHNmz9TIBXM0cvZONawqtatXUo3iwuXrw/IWAOAEhEIAQIHZd/iMNuxIkqdLca0puPakdib6qXSFOHW6rbtdRqJChQoqrky186abbrLbiRPDNH/+fM2d/b1em7RcYT7b1PJafzW5NkL+vkUnHB47eV4KdXcrAKBoIRQCAApE2fKVNXHVBk1cdVJFQUBwpG5qOUD96tazk8YUte6heVWiRAl1797dbrt27fp9eYupmr5up6mhqugoofb1y7m7EQBQpDjrEw8AUGj++e5wHTt2TEWFmTnU399fCQkJ8vYuOpWxglCxYkUNHjxYd9xxh/bv36+ipnTp0u5uAgAUKYRCAECBCAkJsVtRkpKS4u4meBQTjs36hwCA4s3ZP4UCAAAAgMMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBfdzcAAIDCsGrVak2aNPmK+6SmpurUqVMKCQmRl5dXnl4vNDREN93URI0aNVJgYGCenssJEhIStGjRIq1b97MuXkxRcZbb4+zWW/vq+uuvL9C2AXAmQiEAwBEmTJikL77YoZCQa66wV6ouXvSRj4+PpLyFwtTUPfryy3+odGl/tW3bUC1bNicgZhEE4+MXavnyX3X8uJ9SUq6Tl1eQirecH2enTm1QUNBUQiGAAkEoBAA4RmhoLVWv/vQVKzjnzp2Vv39AniuFxpkzB5SYuFBffbVI//3v/wfEFi2aqXHjxo4MiJkFQamBIiP/rCpVGsnHJ1jFXW6Osy1bXirwdgFwLkIhAAAFJDAwVmXL9pXU1wbEo0cX/R4Q37QBsU2bBraCWNwDogmCCxcutEFwxYotOnbMT15ezgqCAODJCIUAABRSQCxTpo+kPjp79qASExfp668X6ptv3lRMjKkgNkjrYhoUVPS7Tx48eDCtImiC4PHj/r9XBHuqalUTBIv+ewSA4oJQCABAIQsIKK0yZXpL6p1pQGzTpn5aBbEoBUQTBE1FcO7cRWlB0MuroSIiev5eESw67wUAnIRQCACAxwTEBBsQR40yAfEtlS7tl6GLqScGxAMHDvzeNXSRVq7cqhMn0gfBxvLxKb7dYgGguCAUAgDgIQICYlSmTC9JvdIFxEU2IMbE+GWoIAYHB3tgEOz9e0WQIAgARQmhEACAIhIQR49epDFj/pkWEM0spjfeeGOhBMT9+/fbMYJz5izUqlXbbNdQb+9GiozsoypVGhIEAaAIIxQCAFCkAuIhO4vp6NELNWbM2ypVytdOUlMQAdEVBGfPXqDVq3/7fYxgI0VF9VXVqgRBACguCIUAABQhAQGlFBvb026ZBcTWreurVav/dTENCQnJVRA0XUNNRTBjEOxHEASAYopQCABAMQiI584dtl1Mv/lmob79NmcBcd++fWljBP8XBAN+7xpKEAQAJyAUAgBQDPj7Rys29ha7/X9AXJQWEFu1qmcDouliagKiKwjOmbNIa9akD4K3qmrVBgRBAHAQQiEAx0hOTtamTZsUFxfn1pkbAXcExDFjFmncuHdsQKxUqbQ2bdqbLgj2/z0IBri76QBQpCUX0e8ahEIAjmFO0g0aNNDKlStVv359dzcHcEtA9Do1Q42Tx+to8P0qWbI9QRAA8lFR/a7h7e4GAACAwguIcWXr6I/XzVPVUuUJhAAAi1AIAAAAAA5GKAQAAAAAByMUAgAAAICDFdlQWLlyZXl5eWnHjh3ubgoAAAAAFFlFNhQCAAAAAPKOUAgAAAAADkYoBAAAAAAH8+hQuGHDBvXr10/R0dEKCgrS9ddfr7feeksXL1686jjDyZMnq23btoqKirK3zZs3z+7TunXrDH++1EsvvWTvN5dZ3b5v3z7de++9Klu2bFq7Ro4cmWHRyoEDByo2NlaBgYG64YYbNGbMmExfb//+/Xr00UdVs2ZNu29wcLAqVKigdu3a2fcKAAAAAAXJVx5q4cKF6tSpk06dOqWqVauqffv2Onz4sJ599lktXbr0io/95z//qffff18NGza0z2FCnI+PT760a9euXWrQoIH8/f3VokULHTp0SD/++KMNiceOHVOzZs3UoUMHGxjbtGmjnTt3asmSJRowYIB9fP/+/dOe68CBA7aNpn0VK1a0bTXB0Px5zZo1Wrlypf785z/nS7sBAAAAoMiEwjNnzthKmwmEf/rTn2zFzBXq1q1bZ6toJiBmZfjw4bZS2KNHj3xv22effaYHHnhA7733nnx9//fXN3XqVPtaL7/8sq1MPvXUUza8msqi8e6779r38fzzz2cIhf/5z39sABw6dKg++uijtP2N8+fP27AJAAAAAI4LhePHj9fu3bttN8p//OMfGap8derU0XPPPadhw4Zl+fjBgwcXSCA0TEXvnXfeSQuERvfu3W27TGCtVatWhkBo/PGPf9Rf//pXbd261VYazXMYBw8etJemQph+f8PPz8+G3ys5e/as3VxOnDiRb+8TKI5Onz5tLzdu3OjupsANTHf9M2cCdPFisnx8gt3dHCBHUlLOa+/ew1q1apW7m4IiICUlRYmJibZY4e3t0aPFip2Nv3/HcH3nKCo8MhS6xvvdeuutNhxlFvquFAr79u1bYG0zXUJNF89L1ahRw4bCzp07XxbwTIA04x3Nf05XV1GjcePG+vDDD/X0008rNTXVdjsNDQ3Ndltef/11W50EkD2udU0HDRrk7qbAjSpUuEvh4fXd3QwgR86dO6wPPviPPvjgA3c3BUA2v3OYYWVFhUeGwj179tjLKlWqZHp/ZGSkwsPDdfz48UzvNwGsoLgC3aVcYS6r+8PCwtK6xrrccccdmjVrlkaNGqU+ffrYiui1116r5s2b22BrJsq5kmeeeUaPPfZYhkqhqa4C0BXPDV9//bWt6sNZPvjgI8XHByg0NM7dTQFyzN8/2vY8uvvuu93dFBQBVArdWykcNGhQgeYRx4TCvDIzgublP9GVXO0/Vk7+45l9zZdT0910+vTpWrRokd3MmEizmW6pEydOzHKSnICAALsByNm5wQTC+vWpFDlNmTJlFBgYRNdRFEne3n4qV64c5y5k+/tsQkKCYmJiCIVFMI+4g0ceJeakl76r16XMLJ9ZVQmvxswaaiQlJWV6v5kttLCZ6uATTzyhSZMm2f/As2fPtv+JzQQ2X375ZaG3BwAAAIBzeGQobNWqlb0cO3asnYXzUnkJSq7AmdlEE8nJyZo7d67cyYxHNBPMmNlXDbM0BQAAAAA4KhSa8XQmvJmZOs24ufRdOtevX69XX3011899880320szUHvv3r1pt5vlL8zSEGbW08Jiwq1Zi/BSporpmmynUqVKhdYeAAAAAM7j7al9cM3kK8HBwXYh+po1a+q2226zs3OavvRm0fjchiUzo6lZMN4Ezuuuu07dunVTly5d7KQ2JogV5gDuCRMm2LaYANy1a1c7KNVcmsliTIXw+uuv13333Vdo7QEAAADgPB4ZCl1dSH/66Sf17t1bR48etROumFlJzXp/Y8aMyfXzmiUuzIyfDz30kJ0RdObMmXYpiV69etm1fwpz9s7HH3/cLmpfvnx5+9rffvutvTRjDN977z0tXbo0bdZSAAAAAHDc7KOmUmYWss9MZpPQZDUxzaUiIiJs6DLbpV566SW7Zfd2l88//9xuWXF1B03PVDzNBgAAAADu4rGVQgAAAABAwSMUAgAAAICDEQoBAAAAwMEIhQAAOMTp07uVcGimvX702E+6cCHJ3U0CAHgAj55oBgAA5D0IJiYuVHLyQvn771J0BS/NSK6no+cnaOee75SaWlfh4c0UGdlEvr7MeA0ATkQoBOAYcXFxWrlypb0EnBQEy5YN0s0336gWLe5UvXr15O/vryaJiVqyZInmzl2oJUve086dHyg19QaFhzcnIAKAw75rEAoBOEZwcLDq16/v7mYABeL06V02CJ46tVABAbszDYLpRUVFqWvXrnZL/D0gzpu3UIsXuwJind8D4k0ERAAo5t81CIUAABThIHjkyAIlJy+yQbBcuWAbBJs3H5xpEMxK+oB49OjRtAri4sXvZ6ggRkQ0kZ9fiQJ/XwCAwkUoBACgiEhNTU2rCF4aBFu0GGKDoJ+fX55eIzIyUl26dLHbsWPHtHjxYs2fv0gLF76vXbs+UErK/1cQCYgAUDwQCgEAKDJBcKECA/eoXLmQ34PgXapbt26eg2BWIiIisgiIH2jXrg8JiABQTBAKAQDwyCC4U4mJizIJgncXaBDMTkA8fvy4DYhmDGLGgNjs94AYXqhtAwDkDaEQAACPCoKuiuBeGwTbt2+i5s3dEwSzEh4ers6dO9vNBETXJDULF36oXbuGKyWldroKIgERADwdoRAAALcHwf9NFpM+CLZoca8Ngr6+nv1RbQJip06d7OYKiKaL6YIFH2bSxZSACACeyLM/aQAAKJZBcEfaZDHpg2DLlvfphhtu8PggmNOAuHDh8N8DoquC2JSACAAepGh+6gAAUMSCYHLydh096hojuE/ly4f+XhEs2kEwOwHxxIkT6bqYfpTWxbREiWaKijIBMcLdzQUARyten0AAAHhcEHSNEdxvg2CHDjepefOhxTIIZqVEiRLq2LGj3UxAXLp0qQ2ICxaM0K5dHxEQAcDNnPFpBACApFOn1mvLluevsEeqLly4KF9fH0leeXqt1NQEBQWZIBj2e0XwAdWpU8cxQfBKAbFDhw52yzwg1pQUqOIt58dZcvJvkmoXeMsAOJOzP5kAAI4xcGB/hYdPv2p17+TJkwoNDZWXV95CYUhIWTVpQhDMbkBMSkqyAXHdunVKSUlRcZa746yeevbsWcAtA+BUfEoBABzh2muvtduVmDCSkJCgmJgYeXt7F1rbIIWFmYpqe7sVdxxnADwNZyIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAADkYoBAAAAAAH83V3A5B/UlNT7eWJEyfc8vopKSlKSkpSYGCgvL35vQH5j2MMBY1jDIWB4wwFjWMM6TOBKyNcCaGwGDH/+Y0KFSq4uykAAAAAPCQjhIeHX3Efr9TsREcUmV+F9u3bp7CwMHl5ebnl1wgTSHfv3q0SJUoU+uuj+OMYQ0HjGENh4DhDQeMYg2FingmEZcuWvWrFmEphMWL+scuXL+/uZtiTDycgFCSOMRQ0jjEUBo4zFDSOMYRfpULoQidjAAAAAHAwQiEAAAAAOBihEPkmICBAL774or0ECgLHGAoaxxgKA8cZChrHGHKKiWYAAAAAwMGoFAIAAACAgxEKAQAAAMDBCIUAAAAA4GCEQuTZt99+q9atWysyMlIhISG64YYb9I9//EPnz593d9NQDAwZMkReXl5X3M6cOePuZsLDbd68We+99549nmrXri1fX1977Lz66qtXfezs2bPVpUsXRUdHKygoSHFxcXruued08uTJQmk7iu8x9tJLL131/LZp06ZCfR/wXOZ71Zw5c/TEE0+oUaNGioiIkJ+fn2JjY9WjRw9Nnz79io/nXIYrYfF65Mmf/vQnvfvuu/bDr23btgoNDVV8fLyeeuopTZ06VTNnzrQnHiCvmjVrpurVq2d6n4+PT6G3B0XL8OHD7bkqp9555x099thj9st5ixYtVLp0aS1YsECvvfaaxo8fr4ULF9ovWEBujzHD/Jhat27dPC08jeJv/vz5at++vb1ugmDz5s3tj/EbNmyw37nMNnToUH300Uf2nJUe5zJclZl9FMiNiRMnmplrU0NDQ1NXrlyZdvuhQ4dSa9eube97/PHH3dpGFH2DBw+2x9Jnn33m7qagCPv4449T//znP6eOGjUqdePGjal33HGHPa5eeeWVLB+zatWqVC8vr1QfH5/UGTNmpN1+6tSp1Hbt2tnH9+nTp5DeAYrjMfbiiy/afcwlcDVz5syx55wff/zxsvu++eYbe64yx9MXX3yR4T7OZcgOKoXINfPrkvH000+rfv36abebX5o+/PBD+0vU+++/rxdeeIFfOgG41b333pvhz97eVx898frrr5sfTnXXXXepc+fOabcHBwdr5MiRqlq1qv2F3XTvM92w4Gy5OcaAnDA9ssyWmf79+2vWrFn23PTll1/qzjvvTLuPcxmygzMWcmXv3r1avny5vT5w4MDL7jddGipUqKCzZ89qxowZbmghAOTeuXPn0sbnZHaOq1Spku3SbEycOLHQ2wcAl6pXr5693L17d9ptnMuQXVQKkSurV6+2l1FRUapSpUqm+zRs2NCemMy+t912WyG3EMXN3Llz9fPPPyspKUklS5ZU48aN7YD5gIAAdzcNxdCvv/6q5OTktHNZZsztZkyO63wI5NaqVatsr5vExETbs8Z8ue/evbvCwsLc3TQUIVu2bLGXZcqUSbuNcxmyi1CIXNm+fbu9rFixYpb7mEph+n2BvDDdYS5lPvg+/fRTderUyS1tQvHlOm+Z2f2y+mLOOQ75xTVJSHomHP773//O0A0QyMqBAwf0+eef2+t9+vRJu51zGbKL7qPIFVOtMcysV1kxM5EaJ06cKLR2ofgxs/KZGf3Wr19vj6WDBw/aWW2bNm2q/fv322m4582b5+5mopjhHIfCUK1aNTs+31RoTJXQbGYWyG7duun48eMaPHiwRo0a5e5mwsNduHBBgwYNsseMWQ7l/vvvT7uPcxmyi0ohAI82bNiwDH82v3SaKblvvvlm9erVS5MnT7ZLo6xZs8ZtbQSA3Ljjjjsuu82M7zJVw0ceecSue2jOgf369ZO/v79b2gjP98ADD9j1C83QinHjxnGsIFeoFCJXXF0QTp06leU+rsVQS5QoUWjtgnOYtZZefvlle33t2rUZBtYDecU5Du5mFrY3a7AeOnRIP/30k7ubAw/16KOP2hlEIyMj7eyjNWvWzHA/5zJkF6EQuVK5cmV7eaUv4q77XPsC+a1WrVpp1/fs2ePWtqB4cZ23jh07ltb96lKc41CQzERuMTEx9jrnN2Tm8ccft+NOzXhBM6zCNftoepzLkF2EQuSK68Rz5MiRLAcmr1ixwl6mX8MQyE/m+HNhlj7kp2uuucau4ZX+XHYpznEoSBcvXrRjxAzOb7jUk08+qbfffttOSGQCYVYzi3IuQ3YRCpEr5cuXV6NGjez10aNHX3a/GShvfnkyywWYZQOAgvDNN9+kdXkxH3xAfjFjcrp27ZrlOW7nzp1avHixvW7GtgL5bcqUKXYpAdNVPqsv/HAms3zJm2++aQOh6TLq+j6WGc5lyC5CIXLt2WeftZdvvPGGXWMpffXmwQcftNcfeughe9ICcsNMHmO+GJmZ1dJLSUmxYyhcx6CZkMHPz89NrURx/uJlvpB/9tln+v7779NuN1/U77nnHlvJMVO/x8XFubWdKJp27dqlr7/+WmfOnLnsvkmTJunee++112+//XbFxsa6oYXwRM8//7z+/ve/2y6jVwuELpzLkB1eqampqdnaE8higLPpz26+kLdr185OeWxmwDJ9180MauaEFRQU5O5moogyX4zML5dmAL3p1lK6dGl7bJnlKcwXKuO2226zaxj6+jKZMrJmfrhy/VhlbNu2TYcPH7a9HsqVK5d2+8SJEzMs/PzOO+/oscces1+oWrVqZcd4mUWezXIopjptekVER0cX+vtB0T/GzI9eZiiGWQ7AXJp9Tp8+rQ0bNqQtQt6mTRv7w5hryQA4mzkWbrnlFnvdVI+vu+66TPcz56S33norw22cy3A1hELk2dixY/XBBx/YD7jz58/bdZfMejlmGm2mRUZemPGq5kcHM97BXDdVaHPKMuGwcePGuuuuu+iejGwxa1maL9hXY46zSydbmD17tv75z39q2bJldga/ihUrqm/fvnrmmWcY64VcH2PmfGa6AC5fvlxbt261fz537pz9Yt6gQQMNHDhQ/fv3l7c3nbrwP2ZxevO5dzWVKlXSjh07LrudcxmuhFAIAAAAAA7Gz08AAAAA4GCEQgAAAABwMEIhAAAAADgYoRAAAAAAHIxQCAAAAAAORigEAAAAAAcjFAIAAACAgxEKAQAAAMDBCIUAAGRiy5Yteuihh3TttdcqJCREgYGBKl++vBo1amRvHz9+/GWPad26tby8vDJs5rFlypRRs2bN9PDDDys+Pl6pqalZvu6QIUMuew5fX19FR0erVatW+uCDD3T+/Pk8vbd3333XPm9m7+FKXnrpJfs4c5ne559/flmbzebn52ffe/fu3TV9+vRMn3PhwoV23yeffDJP7wkAkHu+eXgsAADF0oQJEzRw4ECdPXtWJUuWtIGuVKlSOnr0qNasWWOD2TfffKM+ffpk+vgbbrhBdevWtdfPnTunI0eOaO3atVq8eLHef/991alTxwapevXqZdmGatWqqXnz5vb6mTNntGnTJv344492++9//6tZs2YpKCgox+/t0KFDNtSZcJtV+3PLBOC+ffum/TkpKUm//PKLpk2bZrenn35ar7/+eobHmPfYtWtXG1Tvu+8+1ahRI1/bBAC4OkIhAADpHDx4UIMHD7aB8PHHH9err75qq4TprVy5UuPGjcvyOXr27HlZNc1YsGCB/vznP2vZsmU2DM2fP18NGzbM9DnM/SY4pmeC6G233aZFixbZcPnEE0/k+P29/PLLOnbsWKbtyytTzby0zcY777yjxx57TH//+99t2K5du/ZlbTKVxKeeesoGcgBA4aL7KAAA6ZiK1smTJ1W2bFm99dZblwVCo0GDBpdVvLKjRYsWNhiawJecnGwD0sWLF7P9+AEDBqh9+/b2+tSpU3P8+iYMmtBWrlw5derUSYVl2LBhtuut6TZrus9m9vdpqquTJ0/Wjh07Cq1dAID/IRQCAHBJpdAw3UULgr+/vz766KO0cYuTJk3K0eNN19P07cyJzz77TKdOndIdd9whb+/MvwKcPn3aVhFNN86AgAA7JtBUTnft2qW8KF26tL28cOFClmMpU1JSNHz48Dy9DgAg5wiFAACkU7FiRXu5fv16zZkzp0Be47rrrksbT2jGBubEiRMnMoSsnHAF0JtvvjnT+031sm3btrY75/79+9WhQwdb3fzhhx9Uv359bd++Xblx/Phxbd68Oe29Z8ZVAc1pSAYA5B1jCgEAuGQ8oOleuXfvXhtUzIyf7dq1s6HITM6SXxVE02Vy9erVdiKW7DLjHGfPnm2v9+jRI0evZyqAS5cutRXCxo0bZ7rPiy++aPeJi4uzgdh0oTVcXV2//PLLHL2m6YZr3t8zzzxjr990003q2LFjpvuaWV4jIiL066+/as+ePba7KQCgcFApBAAgndDQUBuIbrzxRjsGbt68eXrhhRfsDJkxMTG2wme6f+ZkLGBWk7IYZmbS7IRBM+upmS3UVOtMWDXLYuSECWdmJlQTtsLCwjINjSNGjEibGMYVCI3g4GD7njMbX5nezp07MyxJYV6nSZMmdtZV83doAq25PTPm9lq1atnrq1atytF7AwDkDZVCAAAucc0119iKmZkl1MyK+dNPP9mgYpZzMOHsD3/4g13jz9xnxgjmhhk/Z2QVkr744gu7XeqBBx6wS2JkNSYwK64xiGaJjcyY92eWkDBhNbNJaGJjY2130ilTpmR7SQoTQnfv3q0lS5bo7bfftqHy2WefzfLxrrblZrwkACD3CIUAAGTBdLN0dbU0VUPT3fPNN9+0S0OYqpdZWy83y0IYhw8ftpdRUVFXXafQjCNcsWKFDVimYmeWdHjwwQdzPK7PKFGiRKb3my6bRuXKlbN8jipVquRqSQozoU7r1q313HPP2clrzFIfmXG1zawHCQAoPHQfBQAgG0xFz4wrNAvHu8bz5WVSFFcXyUvX7Lt0nUKzmbX7TLdRVwD905/+pLVr1+bo9cx4vfQT1RQmM5OpWbjeeOONN64aXCMjIwutbQAAQiEAADlmulGmr/bllBnfZ7qhpn+uq/Hx8bGLv7ds2VLnz5/PstqWFTMe8kpjGM3kOsaV1gnMyxqCVatWTfs7y+rvzdW23MysCgDIPUIhAADpmG6iV+Nasy83M2SacXZmXKBhZvnMySyiplppJoExl2YynLlz52b7sWYpCDP+0XQTNWMHM5sN1UyyYwLbzJkzL7vfjPPL7Pbs2rZtm700YyGDgoIyHWO5cePGtLYAAAoPoRAAgHQ+/PBDu1i7mTEzs8BounK+//779s8DBgzI0XMvWrTIrvu3cOFCG8BGjRqV4wljTBfWfv36pS0hkV0miJmZQE34MhPnZHb/0KFD7fVhw4bZdQrTz0xqJtcxl7lhxhSaKqdrjUQzIU1m1VPTfbRmzZppVUsAQOFgohkAANIxXTPNenxmM2sSmiUozAQqx44d04YNG9K6UA4aNEj33HNPps9hxhq69jPPl5iYaLuLHjhwwN52ww032LGCdevWzVUbX331VRtOFyxYoFmzZqUt/J6dNRh//PFH+5jMFrD/61//agOrmXXVhLM2bdrYGUPN65j3ceedd15xrUJTZRwyZEims4+aJTwqVqyo4cOHZ/pY1/qLpo0AgMJFKAQAIB0T9Mwsm6Z7pqmomSBouk76+vratftuu+02G44yW7bBxUwC45oIxlTgwsPD7XOa5Rp69eplw1ZWS1Fkd+IW006zrqCpFmY3FN511112vcCvv/5ar732mh2nmJ6p4JkuqWYymNGjR+uHH36wk76YAGmCaGYzi6Z36tSpDMtomPdoZhQ13UFNN9mHH344y9lPzeNM1dRUJAEAhcsrNTuDJwAAQLFgFr036xya9Qa7d+8uT7By5Uo1bNjQBmZTAQUAFC5CIQAADnLo0CHbNbR69epavny5PEHXrl1t99H169fbKigAoHAx0QwAAA5ixkm+9NJLWrFihcaNG+fu5tgxjDNmzNCjjz5KIAQAN6FSCAAAAAAORqUQAAAAAByMUAgAAAAADkYoBAAAAAAHIxQCAAAAgIMRCgEAAADAwQiFAAAAAOBghEIAAAAAcDBCIQAAAAA4GKEQAAAAAByMUAgAAAAAcq7/AyHNHsxj5Ov6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sdr_results(sdr_collection, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAE_Selected_Topics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
