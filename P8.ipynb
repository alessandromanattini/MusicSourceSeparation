{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f74d155",
   "metadata": {},
   "source": [
    "**DSP DEMIXING**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd09d18",
   "metadata": {},
   "source": [
    "Let's start with loading the dataset. The folder \"musdbhq_trimmed\" contains 30 seconda of all the tracks. Since we noticed that not all the stems of the tracks were non-silent in the first 30 seconds, we trimmed the dataset in order to retrieve 30 seconds of each track where every stem is non-silent, in order to have a more accurate measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4989528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm, os, torchaudio\n",
    "\n",
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load the dataset from the musdb18hq_trimmed folder.\n",
    "    Each subfolder in the dataset corresponds to a song.\n",
    "    Each song contains multiple stems (e.g., mixture, drums, bass, etc.).\n",
    "    Returns:\n",
    "        dataset_dict (dict): A dictionary where keys are track folders and values are dictionaries of stems.\n",
    "    \"\"\"\n",
    "    dataset_dict = {}\n",
    "\n",
    "    for track_folder in tqdm.tqdm(os.listdir(\"/Users/alessandromanattini/Desktop/MAE/SELECTED TOPIC/PROJECT STMAE/musdb18hq_trimmed\")):\n",
    "        track_path = os.path.join(\"/Users/alessandromanattini/Desktop/MAE/SELECTED TOPIC/PROJECT STMAE/musdb18hq_trimmed\", track_folder)\n",
    "        if not os.path.isdir(track_path):\n",
    "            continue\n",
    "\n",
    "        # Prepare a sub-dictionary for this song\n",
    "        stems_dict = {}\n",
    "        \n",
    "        for stem_name in [\"mixture\", \"drums\", \"bass\", \"vocals\", \"other\", \"new_mixture\"]:\n",
    "            file_path = os.path.abspath(os.path.join(track_path, f\"{stem_name}.wav\"))\n",
    "            \n",
    "            if not os.path.isfile(file_path):\n",
    "                print(f\"Warning: file not found {file_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load full audio\n",
    "            waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "            stems_dict[stem_name] = waveform\n",
    "            \n",
    "        dataset_dict[track_folder] = stems_dict\n",
    "        \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42af704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset_dict = load_dataset()  \n",
    "\n",
    "print(\"Number of keys in dataset_dict:\", len(dataset_dict))\n",
    "\n",
    "# Check the first track folder and its contents\n",
    "first_track_folder = list(dataset_dict.keys())[0]\n",
    "print(\"First track folder:\", first_track_folder)\n",
    "print(\"Contents of the first track folder:\")\n",
    "for stem_name in dataset_dict[first_track_folder].keys():\n",
    "    print(f\" - {stem_name}: {dataset_dict[first_track_folder][stem_name].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c08eb",
   "metadata": {},
   "source": [
    "Let's load all the mixtures in a list ***mixture_files[]***.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all new_mixture.wav files \n",
    "mixture_files = []\n",
    "for track_folder in dataset_dict.keys():\n",
    "    new_mixture_path = os.path.join(\"/Users/alessandromanattini/Desktop/MAE/SELECTED TOPIC/PROJECT STMAE/musdb18hq_trimmed\", track_folder, \"new_mixture.wav\")\n",
    "    if os.path.isfile(new_mixture_path):\n",
    "        mixture_files.append(new_mixture_path)\n",
    "    else:\n",
    "        print(f\"Warning: file not found {new_mixture_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3005ae5",
   "metadata": {},
   "source": [
    "Define the parameters of the STFT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3825ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "# STFT parameters\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "win = 'hann'\n",
    "\n",
    "# Initialize lists to store STFT results\n",
    "S_full_list = []\n",
    "phase_list = []\n",
    "\n",
    "# Loop through each mixture file and compute STFT\n",
    "for mixture_path in mixture_files:\n",
    "    # Carica l'audio dal file\n",
    "    audio, sr = librosa.load(mixture_path, sr=None)\n",
    "    # Calcola STFT\n",
    "    D = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length, window=win)\n",
    "    # Estrai modulo e fase\n",
    "    mag, phase = librosa.magphase(D)\n",
    "    \n",
    "    S_full_list.append(mag)\n",
    "    phase_list.append(phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b269a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules for SDR computation\n",
    "try:\n",
    "    from mir_eval.separation import bss_eval_sources\n",
    "except ImportError:\n",
    "    print(\"Installing mir_eval...\")\n",
    "    %pip install mir_eval\n",
    "    from mir_eval.separation import bss_eval_sources\n",
    "\n",
    "def compute_sdr(original, separated, sr):\n",
    "    \"\"\"\n",
    "    Compute Signal-to-Distortion Ratio (SDR) between original and separated signals.\n",
    "    \"\"\"\n",
    "    sdr, _, _, _ = bss_eval_sources(\n",
    "        np.array([original]), \n",
    "        np.array([separated]), \n",
    "        compute_permutation=True\n",
    "    )\n",
    "    return sdr[0]  # Return SDR for the first source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c87c58",
   "metadata": {},
   "source": [
    "**DRUMS EXTRACTION**\n",
    "(using HPSS):\n",
    "\n",
    "- STFT Magnitude Input: The function receives the magnitude (mix_mag) and phase (mix_phase) of the mixture’s STFT.\n",
    "\n",
    "- HPSS Decomposition: It utilizes the **Harmonic-Percussive Source Separation (HPSS)** algorithm to split the mixture’s magnitude into two components:\n",
    "    1) A ***harmonic component*** that captures the tonal content.\n",
    "    2) A ***percussive component*** that emphasizes transient, drum-like features.\n",
    "\n",
    "- Drums Reconstruction: The function then reconstructs the time-domain drums signal by combining the percussive component with the original phase information using the iSTFT.\n",
    "\n",
    "- Output: The result is a time-domain signal (drums) that represents the extracted percussive (drum) elements from the mixture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18378f04",
   "metadata": {},
   "source": [
    "**Vocal Extraction** (using REPET-SIM):\n",
    "\n",
    "- STFT Magnitude Input: Similar to the drums extraction, this function takes the mixture’s magnitude (mix_mag) and phase (mix_phase) as input.\n",
    "\n",
    "- NN Filter Processing: The function applies a ***nearest-neighbor (nn) filter*** to the magnitude. This filter:\n",
    "    - Uses a median aggregation to estimate a smooth background signal.\n",
    "    - Operates with a cosine similarity metric and a time window (converted from 2.0 seconds into frames) to capture repeating patterns.\n",
    "\n",
    "- Filter Application: The filtered version (S_filter) is then constrained by taking the element-wise minimum with the original magnitude, ensuring that only components present in both are retained.\n",
    "\n",
    "- Soft Mask Creation: A soft mask is computed using librosa.util.softmask that emphasizes differences between the original magnitude and the filtered background. This mask is tuned (with a factor of 100 and power 2) to highlight vocal components.\n",
    "\n",
    "- Vocals Reconstruction: The function applies this mask to the original magnitude to produce a modified magnitude focused on the vocal content. It then reconstructs the time-domain vocal signal by combining this modified magnitude with the original phase via the iSTFT.\n",
    "\n",
    "- Output: The final output is a time-domain signal representing the extracted vocals from the mixture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a279da80",
   "metadata": {},
   "source": [
    "**BASS EXTRACTION**\n",
    "\n",
    "For bass components, we simply applied a low-pass filter to retrieve the low frequency components.\n",
    "\n",
    "**OTHER EXTRACTION**\n",
    "Finally we use a subtractive approach to retrieve the other component. \n",
    "We define :   \n",
    "\n",
    "***y_other = y - y_drums - y_vocals - y_bass***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c826f9",
   "metadata": {},
   "source": [
    "Now we are going to do the separation for just a random track of the dataset to see the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85ac2e",
   "metadata": {},
   "source": [
    "Single Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780cfa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "# Perform extraction for the first mixture and listen to the results\n",
    "mixture_path = mixture_files[49]\n",
    "mixture, sr = librosa.load(mixture_path, sr=None)\n",
    "\n",
    "# Play the mixture\n",
    "ipd.display(ipd.Audio(mixture, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f51c6",
   "metadata": {},
   "source": [
    "# DSP-Based Source Separation\n",
    "\n",
    "## Overview\n",
    "A classical digital signal processing approach that combines multiple techniques for audio source separation without machine learning.\n",
    "\n",
    "## Function Overview: `separate_sources_v2`\n",
    "\n",
    "### 1. **Initial HPSS Decomposition**\n",
    "- Uses **Harmonic-Percussive Source Separation** to split the mixture into:\n",
    "  - **Harmonic component**: Captures tonal/pitched content (vocals, bass, other instruments)\n",
    "  - **Percussive component**: Emphasizes transient, drum-like features\n",
    "\n",
    "### 2. **Drums Extraction (Enhanced HPSS)**\n",
    "- Starts with percussive component from HPSS\n",
    "- **Vocal frequency cleaning**: Attenuates 300-3000 Hz range to remove vocal bleed\n",
    "- Applies attenuation factor (0.4) to reduce vocal artifacts in drum track\n",
    "- Reconstructs cleaned drum signal using original phase\n",
    "\n",
    "### 3. **Bass Extraction (Low-pass Filtering)**\n",
    "- Applies Butterworth low-pass filter to harmonic component\n",
    "- **Cutoff frequency**: 200 Hz (captures fundamental bass frequencies)\n",
    "- **Filter order**: 4th order for sharp frequency rolloff\n",
    "\n",
    "### 4. **Vocals Extraction (REPET-SIM)**\n",
    "- Uses **nearest-neighbor filtering** on harmonic component\n",
    "- **Repeating pattern removal**: Identifies and removes instrumental patterns\n",
    "- **Cosine similarity**: Compares spectral frames over 2-second windows\n",
    "- **Vocal isolation**: Extracts non-repetitive content (vocals) from repetitive background\n",
    "\n",
    "### 5. **Other Component (Subtractive)**\n",
    "- Calculates residual: `y_other = y_mixture - y_drums - y_bass - y_vocals`\n",
    "- Captures remaining instruments and ambient sounds\n",
    "\n",
    "## Key Features\n",
    "- **No training required**: Uses classical DSP techniques\n",
    "- **Real-time capable**: Computationally efficient\n",
    "- **Frequency-aware**: Each method targets appropriate frequency ranges\n",
    "- **Artifact reduction**: Includes vocal cleaning step for drums\n",
    "- **Visualization**: Generates spectrograms for each separated component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "\n",
    "def separate_sources_v2( # Rinomino la funzione per chiarezza\n",
    "    mixture_path,\n",
    "    sr=None,\n",
    "    hpss_margin=1.0, # Leggermente aumentato come punto di partenza\n",
    "    hpss_power=2.0,\n",
    "    # Parametri per la pulizia delle voci dalla batteria\n",
    "    drum_clean_vocal_freq_min=300.0,  # Hz, inizio range vocale da attenuare\n",
    "    drum_clean_vocal_freq_max=3000.0,  # Hz, fine range vocale da attenuare\n",
    "    drum_clean_vocal_atten_factor=0.4, # Fattore di attenuazione (0.0 = muto, 1.0 = nessun cambiamento)\n",
    "    # Parametri per il basso\n",
    "    bass_cutoff=200.0,\n",
    "    bass_order=4,\n",
    "    # Parametri per la separazione vocale principale\n",
    "    nn_width_vocals_sec=2.0 # Aumentato per una migliore separazione vocale\n",
    "):\n",
    "    \"\"\"\n",
    "    Carica un file audio e lo separa in batteria, basso, voci e altro,\n",
    "    con un passaggio dedicato per pulire i residui vocali dalla batteria.\n",
    "    Restituisce un dizionario di array numpy (tutti mono).\n",
    "    \"\"\"\n",
    "    # 1) Caricamento e conversione in mono\n",
    "    y, sr_loaded = librosa.load(mixture_path, sr=sr)\n",
    "    if sr is None: # Se sr non era specificato, usa quello del file\n",
    "        sr = sr_loaded\n",
    "        \n",
    "    if y.ndim > 1:\n",
    "        y = librosa.to_mono(y)\n",
    "\n",
    "    # 2) HPSS per l'estrazione iniziale di batteria e componente armonica\n",
    "    # Calcola lo STFT del mix originale\n",
    "    D_mixture = librosa.stft(y)\n",
    "    n_fft = (D_mixture.shape[0] - 1) * 2 # Infer n_fft dallo spettrogramma\n",
    "    \n",
    "    D_harmonic_mixture, D_percussive_mixture = librosa.decompose.hpss(\n",
    "        D_mixture, \n",
    "        margin=hpss_margin, \n",
    "        power=hpss_power\n",
    "    )\n",
    "    \n",
    "    # Componente armonica generale (verrà usata per basso e voci)\n",
    "    y_harmonic_overall = librosa.istft(D_harmonic_mixture, length=len(y))\n",
    "\n",
    "    # --- 3) Pulizia della Batteria dai Residui Vocali ---\n",
    "    # Partiamo da D_percussive_mixture (lo spettrogramma della batteria da HPSS)\n",
    "    D_perc_mag, D_perc_phase = librosa.magphase(D_percussive_mixture)\n",
    "    \n",
    "    # Crea una copia della magnitudine per la modifica\n",
    "    D_perc_mag_cleaned = np.copy(D_perc_mag)\n",
    "    \n",
    "    # Ottieni le frequenze corrispondenti ai bin dello STFT\n",
    "    frequencies = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
    "    \n",
    "    # Applica l'attenuazione nel range di frequenza vocale definito\n",
    "    for i, freq_bin in enumerate(frequencies):\n",
    "        if drum_clean_vocal_freq_min <= freq_bin <= drum_clean_vocal_freq_max:\n",
    "            D_perc_mag_cleaned[i, :] *= drum_clean_vocal_atten_factor\n",
    "            \n",
    "    # Ricostruisci lo spettrogramma della batteria pulita\n",
    "    D_drums_cleaned_stft = D_perc_mag_cleaned * D_perc_phase\n",
    "    y_drums = librosa.istft(D_drums_cleaned_stft, length=len(y))\n",
    "\n",
    "    # --- 4) Estrazione del Basso dalla componente armonica generale ---\n",
    "    # Applica un filtro passa-basso a y_harmonic_overall\n",
    "    nyquist = 0.5 * sr\n",
    "    # Assicurati che bass_cutoff sia sotto la frequenza di Nyquist\n",
    "    actual_bass_cutoff = min(bass_cutoff, nyquist - 1) # -1 per sicurezza\n",
    "    if actual_bass_cutoff <= 0:\n",
    "        print(f\"Attenzione: bass_cutoff ({bass_cutoff} Hz) non valido con sr={sr} Hz. Il basso non verrà filtrato.\")\n",
    "        y_bass = np.zeros_like(y_harmonic_overall) # o gestisci diversamente\n",
    "    else:\n",
    "        b, a = scipy.signal.butter(bass_order, actual_bass_cutoff / nyquist, btype='low', analog=False)\n",
    "        y_bass = scipy.signal.lfilter(b, a, y_harmonic_overall)\n",
    "\n",
    "    # --- 5) Estrazione delle Voci dalla componente armonica generale ---\n",
    "    # Nota: per una migliore separazione, si potrebbe sottrarre il basso stimato\n",
    "    # da y_harmonic_overall prima di cercare le voci, ma per semplicità usiamo y_harmonic_overall.\n",
    "    # y_harmonic_minus_bass = y_harmonic_overall - y_bass # Opzionale, potrebbe aiutare\n",
    "    \n",
    "    S_harmonic_overall, phase_harmonic_overall = librosa.magphase(librosa.stft(y_harmonic_overall)) # o di y_harmonic_minus_bass\n",
    "    \n",
    "    width_vocals_frames = int(librosa.time_to_frames(nn_width_vocals_sec, sr=sr, n_fft=n_fft))\n",
    "    \n",
    "    S_instrumental_repeating = librosa.decompose.nn_filter(\n",
    "        S_harmonic_overall, \n",
    "        aggregate=np.median, \n",
    "        metric='cosine', \n",
    "        width=width_vocals_frames\n",
    "    )\n",
    "    \n",
    "    # La maschera per le voci è ciò che NON è ripetitivo nella componente armonica\n",
    "    S_vocals_mag = np.clip(S_harmonic_overall - S_instrumental_repeating, 0, None)\n",
    "    \n",
    "    y_vocals = librosa.istft(S_vocals_mag * phase_harmonic_overall, length=len(y))\n",
    "\n",
    "    # --- 6) Calcolo del Residuo \"Other\" ---\n",
    "    # Sottrai le componenti stimate dal mix originale\n",
    "    y_other = y - y_drums - y_bass - y_vocals\n",
    "\n",
    "    # Plot the spectrograms for visualization\n",
    "    import matplotlib.pyplot as plt\n",
    "    def plot_spectrogram(y, sr, title):\n",
    "        D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    # Plot spectrograms for each component\n",
    "    # plot_spectrogram(y_drums, sr, \"Drums Spectrogram\")\n",
    "    # plot_spectrogram(y_bass, sr, \"Bass Spectrogram\")\n",
    "    # plot_spectrogram(y_vocals, sr, \"Vocals Spectrogram\")\n",
    "    # plot_spectrogram(y_other, sr, \"Other Spectrogram\")\n",
    "    # # Plot the original mixture for comparison\n",
    "    # plot_spectrogram(y, sr, \"Original Mixture Spectrogram\")\n",
    "\n",
    "    return {\n",
    "        'drums': y_drums,\n",
    "        'bass': y_bass,\n",
    "        'vocals': y_vocals,\n",
    "        'other': y_other,\n",
    "        'sr': sr\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = separate_sources_v2(mixture_path)\n",
    "drums  = sources['drums']\n",
    "bass   = sources['bass']\n",
    "vocals = sources['vocals']\n",
    "other  = sources['other']\n",
    "\n",
    "# play mixture\n",
    "print(\"Mixture:\")\n",
    "display(ipd.Audio(mixture, rate=sr))\n",
    "\n",
    "# Play the separated components\n",
    "print(\"Drums Component:\")\n",
    "display(ipd.Audio(drums, rate=sources['sr']))\n",
    "print(\"Bass Component:\")\n",
    "display(ipd.Audio(bass, rate=sources['sr']))\n",
    "print(\"Vocals Component:\")\n",
    "display(ipd.Audio(vocals, rate=sources['sr']))\n",
    "print(\"Other Component:\")\n",
    "display(ipd.Audio(other, rate=sources['sr']))\n",
    "\n",
    "# Plot the spectrogram of the original components and the separated components\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the track name from the mixture path\n",
    "track_name = mixture_path.split('/')[-2]  # Extract folder name from path\n",
    "\n",
    "# Load original stems from dataset_dict\n",
    "original_stems = dataset_dict[track_name]\n",
    "\n",
    "def plot_spectrogram_comparison(original_audio, separated_audio, stem_name, sr, \n",
    "                              original_title=\"Original\", separated_title=\"Separated\"):\n",
    "    \"\"\"\n",
    "    Plot side-by-side spectrograms for comparison\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Convert tensors to numpy if needed and handle dimensions\n",
    "    if hasattr(original_audio, 'numpy'):\n",
    "        original_np = original_audio.numpy()\n",
    "    else:\n",
    "        original_np = original_audio\n",
    "    \n",
    "    if original_np.ndim == 2:\n",
    "        original_np = np.mean(original_np, axis=0)  # Convert to mono\n",
    "    \n",
    "    if separated_audio.ndim == 2:\n",
    "        separated_np = np.mean(separated_audio, axis=0)  # Convert to mono\n",
    "    else:\n",
    "        separated_np = separated_audio\n",
    "    \n",
    "    # Ensure same length for comparison\n",
    "    min_len = min(len(original_np), len(separated_np))\n",
    "    original_np = original_np[:min_len]\n",
    "    separated_np = separated_np[:min_len]\n",
    "    \n",
    "    # Compute spectrograms\n",
    "    D_original = librosa.stft(original_np)\n",
    "    D_separated = librosa.stft(separated_np)\n",
    "    \n",
    "    # Convert to dB scale\n",
    "    S_original_db = librosa.amplitude_to_db(np.abs(D_original), ref=np.max)\n",
    "    S_separated_db = librosa.amplitude_to_db(np.abs(D_separated), ref=np.max)\n",
    "    \n",
    "    # Plot original spectrogram\n",
    "    img1 = librosa.display.specshow(S_original_db, sr=sr, x_axis='time', y_axis='hz', \n",
    "                                    ax=axes[0], cmap='viridis')\n",
    "    axes[0].set_title(f'{original_title} {stem_name.capitalize()}')\n",
    "    axes[0].set_ylabel('Frequency (Hz)')\n",
    "    plt.colorbar(img1, ax=axes[0], format='%+2.0f dB')\n",
    "    \n",
    "    # Plot separated spectrogram\n",
    "    img2 = librosa.display.specshow(S_separated_db, sr=sr, x_axis='time', y_axis='hz', \n",
    "                                    ax=axes[1], cmap='viridis')\n",
    "    axes[1].set_title(f'{separated_title} {stem_name.capitalize()}')\n",
    "    axes[1].set_ylabel('Frequency (Hz)')\n",
    "    plt.colorbar(img2, ax=axes[1], format='%+2.0f dB')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute and display similarity metrics\n",
    "    mse = np.mean((S_original_db - S_separated_db)**2)\n",
    "    correlation = np.corrcoef(S_original_db.flatten(), S_separated_db.flatten())[0, 1]\n",
    "    \n",
    "    print(f\"{stem_name.capitalize()} Spectrogram Analysis:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  Correlation: {correlation:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Create comparison plots for each stem\n",
    "stems_info = [\n",
    "    ('drums', drums, 'Drums'),\n",
    "    ('bass', bass, 'Bass'), \n",
    "    ('vocals', vocals, 'Vocals'),\n",
    "    ('other', other, 'Other')\n",
    "]\n",
    "\n",
    "print(\"=== SPECTROGRAM COMPARISONS ===\\n\")\n",
    "\n",
    "for stem_key, separated_audio, stem_display_name in stems_info:\n",
    "    if stem_key in original_stems:\n",
    "        print(f\"Comparing {stem_display_name}...\")\n",
    "        plot_spectrogram_comparison(\n",
    "            original_stems[stem_key], \n",
    "            separated_audio, \n",
    "            stem_display_name.lower(),\n",
    "            sources['sr'],\n",
    "            \"Ground Truth\",\n",
    "            \"DSP Separated\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Warning: {stem_key} not found in original stems\")\n",
    "\n",
    "# Plot mixture spectrogram for reference\n",
    "print(\"=== MIXTURE SPECTROGRAM ===\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "D_mixture = librosa.stft(mixture)\n",
    "S_mixture_db = librosa.amplitude_to_db(np.abs(D_mixture), ref=np.max)\n",
    "librosa.display.specshow(S_mixture_db, sr=sr, x_axis='time', y_axis='hz', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Original Mixture Spectrogram')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate SDR values\n",
    "sdr_drums = compute_sdr(mixture, sources['drums'], sources['sr'])\n",
    "sdr_bass = compute_sdr(mixture, sources['bass'], sources['sr'])\n",
    "sdr_vocals = compute_sdr(mixture, sources['vocals'], sources['sr'])\n",
    "sdr_other = compute_sdr(mixture, sources['other'], sources['sr'])\n",
    "\n",
    "print(\"=== SDR RESULTS ===\")\n",
    "print(f\"SDR for Drums: {sdr_drums:.2f} dB\")\n",
    "print(f\"SDR for Bass: {sdr_bass:.2f} dB\")\n",
    "print(f\"SDR for Vocals: {sdr_vocals:.2f} dB\")\n",
    "print(f\"SDR for Other: {sdr_other:.2f} dB\")\n",
    "\n",
    "# Create a summary comparison plot\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "# Row 1: Original stems\n",
    "# Row 2: Separated stems\n",
    "for i, (stem_key, separated_audio, stem_display_name) in enumerate(stems_info):\n",
    "    if stem_key in original_stems:\n",
    "        # Original stem (top row)\n",
    "        original_audio = original_stems[stem_key]\n",
    "        if hasattr(original_audio, 'numpy'):\n",
    "            original_np = original_audio.numpy()\n",
    "        else:\n",
    "            original_np = original_audio\n",
    "        \n",
    "        if original_np.ndim == 2:\n",
    "            original_np = np.mean(original_np, axis=0)\n",
    "            \n",
    "        D_orig = librosa.stft(original_np)\n",
    "        S_orig_db = librosa.amplitude_to_db(np.abs(D_orig), ref=np.max)\n",
    "        \n",
    "        img1 = librosa.display.specshow(S_orig_db, sr=sources['sr'], x_axis='time', y_axis='hz', \n",
    "                                        ax=axes[0, i], cmap='viridis')\n",
    "        axes[0, i].set_title(f'Original {stem_display_name}')\n",
    "        \n",
    "        # Separated stem (bottom row)\n",
    "        if separated_audio.ndim == 2:\n",
    "            separated_np = np.mean(separated_audio, axis=0)\n",
    "        else:\n",
    "            separated_np = separated_audio\n",
    "            \n",
    "        min_len = min(len(original_np), len(separated_np))\n",
    "        separated_np = separated_np[:min_len]\n",
    "        \n",
    "        D_sep = librosa.stft(separated_np)\n",
    "        S_sep_db = librosa.amplitude_to_db(np.abs(D_sep), ref=np.max)\n",
    "        \n",
    "        img2 = librosa.display.specshow(S_sep_db, sr=sources['sr'], x_axis='time', y_axis='hz', \n",
    "                                        ax=axes[1, i], cmap='viridis')\n",
    "        axes[1, i].set_title(f'Separated {stem_display_name}')\n",
    "        \n",
    "        # Add colorbars\n",
    "        plt.colorbar(img1, ax=axes[0, i], format='%+2.0f dB')\n",
    "        plt.colorbar(img2, ax=axes[1, i], format='%+2.0f dB')\n",
    "\n",
    "plt.suptitle('Spectrogram Comparison: Original vs Separated Stems', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7c820",
   "metadata": {},
   "source": [
    "# Non-Negative Matrix Factorization (NMF) for Source Separation\n",
    "\n",
    "## What is Non-Negative Matrix Factorization?\n",
    "\n",
    "**Non-Negative Matrix Factorization (NMF)** is a dimensionality reduction technique that decomposes a non-negative matrix **V** into two non-negative matrices **W** and **H**:\n",
    "\n",
    "**V ≈ W × H**\n",
    "\n",
    "Where:\n",
    "- **V**: Original magnitude spectrogram (frequency × time)\n",
    "- **W**: Basis matrix containing spectral templates (frequency × components)  \n",
    "- **H**: Activation matrix showing when each template is active (components × time)\n",
    "\n",
    "In audio source separation, each column of **W** represents a spectral pattern (e.g., drum timbre, vocal formant), and **H** shows their temporal activations.\n",
    "\n",
    "## Function Overview: `separate_sources_v3`\n",
    "\n",
    "### 1. **Audio Loading & STFT**\n",
    "- Loads audio file and converts to mono\n",
    "- Computes Short-Time Fourier Transform (STFT) to get magnitude and phase\n",
    "- Extracts frequency bins for masking\n",
    "\n",
    "### 2. **Frequency-Informed Separation**\n",
    "- Creates frequency masks for each source type:\n",
    "  - **Drums**: 20-8000 Hz (wide range for transients)\n",
    "  - **Vocals**: 80-8000 Hz (human voice range)\n",
    "  - **Bass**: 20-250 Hz (low frequencies)\n",
    "  - **Other**: 200-16000 Hz (mid-high frequencies)\n",
    "\n",
    "### 3. **Hierarchical NMF Processing**\n",
    "- **Initial HPSS**: Separates harmonic and percussive components\n",
    "- **Drums**: Applies NMF to percussive component in drum frequency range\n",
    "- **Bass**: Applies NMF to harmonic component in low frequencies\n",
    "- **Vocals**: Applies NMF to remaining harmonic content (after bass removal)\n",
    "- **Other**: Applies NMF to residual harmonic content\n",
    "\n",
    "### 4. **NMF Algorithm** (`nmf_separate` function)\n",
    "- Extracts frequency band using mask\n",
    "- Runs NMF with specified number of components\n",
    "- Reconstructs separated source: **S_reconstructed = W @ H**\n",
    "- Places result back in full frequency spectrum\n",
    "\n",
    "### 5. **Post-Processing**\n",
    "- **Soft Masking**: Reduces artifacts using probabilistic masks\n",
    "- **Audio Reconstruction**: Combines magnitude with original phase via inverse STFT\n",
    "- **Normalization**: Prevents clipping by scaling to safe levels\n",
    "\n",
    "### Key Advantages\n",
    "- **Learned Patterns**: NMF discovers instrument-specific spectral templates\n",
    "- **Frequency Awareness**: Focuses each model on appropriate frequency ranges\n",
    "- **Flexibility**: Adjustable number of components per source\n",
    "- **Artifact Reduction**: Soft masking maintains audio quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afba719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install mir-eval\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "import warnings\n",
    "try:\n",
    "    from mir_eval.separation import bss_eval_sources\n",
    "except ImportError:\n",
    "    print(\"Installing mir_eval...\")\n",
    "    %pip install mir_eval\n",
    "    from mir_eval.separation import bss_eval_sources\n",
    "\n",
    "def separate_sources_v3(\n",
    "    mixture_path,\n",
    "    sr=None,\n",
    "    n_components_drums=4,      # NMF components for drums\n",
    "    n_components_vocals=6,     # NMF components for vocals  \n",
    "    n_components_bass=3,       # NMF components for bass\n",
    "    n_components_other=5,      # NMF components for other\n",
    "    n_fft=2048,\n",
    "    hop_length=512,\n",
    "    # Frequency ranges for each instrument (Hz)\n",
    "    drums_freq_range=(20, 8000),    # Drums: wide range with emphasis on transients\n",
    "    vocals_freq_range=(80, 8000),   # Vocals: human voice range\n",
    "    bass_freq_range=(20, 250),      # Bass: low frequencies\n",
    "    other_freq_range=(200, 16000),  # Other: mid-high frequencies\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Separate audio sources using Non-negative Matrix Factorization (NMF).\n",
    "    Uses frequency-informed NMF to separate drums, vocals, bass, and other components.\n",
    "    \n",
    "    Returns a dictionary with separated sources.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1) Load audio\n",
    "    y, sr_loaded = librosa.load(mixture_path, sr=sr)\n",
    "    if sr is None:\n",
    "        sr = sr_loaded\n",
    "        \n",
    "    if y.ndim > 1:\n",
    "        y = librosa.to_mono(y)\n",
    "\n",
    "    # 2) Compute STFT\n",
    "    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    S_full = np.abs(D)  # Magnitude spectrogram\n",
    "    phase = np.angle(D)  # Phase information\n",
    "    \n",
    "    # Get frequency bins\n",
    "    freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
    "    \n",
    "    # 3) Create frequency masks for each source type\n",
    "    def create_freq_mask(freq_range):\n",
    "        \"\"\"Create a frequency mask for the given range\"\"\"\n",
    "        mask = (freqs >= freq_range[0]) & (freqs <= freq_range[1])\n",
    "        return mask\n",
    "    \n",
    "    drums_mask = create_freq_mask(drums_freq_range)\n",
    "    vocals_mask = create_freq_mask(vocals_freq_range)\n",
    "    bass_mask = create_freq_mask(bass_freq_range)\n",
    "    other_mask = create_freq_mask(other_freq_range)\n",
    "    \n",
    "    # 4) Apply frequency masking and run NMF on each frequency band\n",
    "    def nmf_separate(S_masked, n_components, mask):\n",
    "        \"\"\"Run NMF on a frequency-masked spectrogram\"\"\"\n",
    "        if not np.any(mask):\n",
    "            return np.zeros_like(S_masked)\n",
    "            \n",
    "        # Extract the relevant frequency band\n",
    "        S_band = S_masked[mask, :]\n",
    "        \n",
    "        if S_band.size == 0 or np.all(S_band == 0):\n",
    "            return np.zeros_like(S_masked)\n",
    "        \n",
    "        # Suppress warnings for convergence\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            \n",
    "            # Run NMF\n",
    "            model = NMF(\n",
    "                n_components=n_components, \n",
    "                init='random', \n",
    "                random_state=random_state,\n",
    "                max_iter=max_iter,\n",
    "                alpha_W=0.1,  # Sparsity for basis vectors\n",
    "                alpha_H=0.1   # Sparsity for activations\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                W = model.fit_transform(S_band)  # Basis spectra\n",
    "                H = model.components_            # Activations\n",
    "                \n",
    "                # Reconstruct the separated component\n",
    "                S_reconstructed = W @ H\n",
    "                \n",
    "                # Create full spectrogram with zeros outside the frequency band\n",
    "                S_separated = np.zeros_like(S_masked)\n",
    "                S_separated[mask, :] = S_reconstructed\n",
    "                \n",
    "                return S_separated\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"NMF failed: {e}\")\n",
    "                return np.zeros_like(S_masked)\n",
    "    \n",
    "    # 5) Separate each source using NMF\n",
    "    print(\"Separating sources with NMF...\")\n",
    "    \n",
    "    # Initial HPSS to help guide separation\n",
    "    S_harmonic, S_percussive = librosa.decompose.hpss(S_full, margin=1.0)\n",
    "    \n",
    "    # Drums: focus on percussive component\n",
    "    S_drums = nmf_separate(S_percussive, n_components_drums, drums_mask)\n",
    "    \n",
    "    # Bass: focus on low frequencies in harmonic component  \n",
    "    S_bass = nmf_separate(S_harmonic, n_components_bass, bass_mask)\n",
    "    \n",
    "    # Vocals: focus on mid frequencies in harmonic component after removing bass\n",
    "    S_harmonic_no_bass = np.maximum(S_harmonic - S_bass, 0.1 * S_harmonic)\n",
    "    S_vocals = nmf_separate(S_harmonic_no_bass, n_components_vocals, vocals_mask)\n",
    "    \n",
    "    # Other: remaining harmonic content\n",
    "    S_remaining = np.maximum(S_harmonic - S_bass - S_vocals, 0.1 * S_harmonic)\n",
    "    S_other = nmf_separate(S_remaining, n_components_other, other_mask)\n",
    "    \n",
    "    # 6) Post-processing: ensure non-negativity and apply soft masks\n",
    "    def apply_soft_mask(S_target, S_mixture, power=2, eps=1e-10):\n",
    "        \"\"\"Apply soft masking to reduce artifacts\"\"\"\n",
    "        mask = (S_target ** power) / (S_mixture ** power + eps)\n",
    "        mask = np.clip(mask, 0, 1)\n",
    "        return mask * S_mixture\n",
    "    \n",
    "    # Apply soft masking to reduce artifacts\n",
    "    S_drums = apply_soft_mask(S_drums, S_full)\n",
    "    S_vocals = apply_soft_mask(S_vocals, S_full) \n",
    "    S_bass = apply_soft_mask(S_bass, S_full)\n",
    "    S_other = apply_soft_mask(S_other, S_full)\n",
    "    \n",
    "    # 7) Reconstruct time-domain signals\n",
    "    def reconstruct_audio(S_mag, phase_orig):\n",
    "        \"\"\"Reconstruct audio from magnitude and phase\"\"\"\n",
    "        S_complex = S_mag * np.exp(1j * phase_orig)\n",
    "        return librosa.istft(S_complex, hop_length=hop_length, length=len(y))\n",
    "    \n",
    "    y_drums = reconstruct_audio(S_drums, phase)\n",
    "    y_vocals = reconstruct_audio(S_vocals, phase)\n",
    "    y_bass = reconstruct_audio(S_bass, phase)\n",
    "    y_other = reconstruct_audio(S_other, phase)\n",
    "    \n",
    "    # 8) Normalize to prevent clipping\n",
    "    def safe_normalize(signal, max_val=0.95):\n",
    "        \"\"\"Normalize signal to prevent clipping\"\"\"\n",
    "        if np.max(np.abs(signal)) > 0:\n",
    "            return max_val * signal / np.max(np.abs(signal))\n",
    "        return signal\n",
    "    \n",
    "    y_drums = safe_normalize(y_drums)\n",
    "    y_vocals = safe_normalize(y_vocals)  \n",
    "    y_bass = safe_normalize(y_bass)\n",
    "    y_other = safe_normalize(y_other)\n",
    "    \n",
    "    return {\n",
    "        'drums': y_drums,\n",
    "        'bass': y_bass,\n",
    "        'vocals': y_vocals,\n",
    "        'other': y_other,\n",
    "        'sr': sr\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c49fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the new function\n",
    "print(\"Testing NMF-based separation...\")\n",
    "sources_nmf = separate_sources_v3(mixture_path)\n",
    "# Compute sdr between original and separated components\n",
    "\n",
    "drums_nmf = sources_nmf['drums']\n",
    "bass_nmf = sources_nmf['bass'] \n",
    "vocals_nmf = sources_nmf['vocals']\n",
    "other_nmf = sources_nmf['other']\n",
    "\n",
    "# Play the separated components\n",
    "print(\"NMF Drums Component:\")\n",
    "display(ipd.Audio(drums_nmf, rate=sources_nmf['sr']))\n",
    "print(\"NMF Bass Component:\")\n",
    "display(ipd.Audio(bass_nmf, rate=sources_nmf['sr']))\n",
    "print(\"NMF Vocals Component:\")\n",
    "display(ipd.Audio(vocals_nmf, rate=sources_nmf['sr']))\n",
    "print(\"NMF Other Component:\")\n",
    "display(ipd.Audio(other_nmf, rate=sources_nmf['sr']))\n",
    "\n",
    "# Create comparison plots for each stem - NMF version\n",
    "stems_info_nmf = [\n",
    "    ('drums', drums_nmf, 'Drums'),\n",
    "    ('bass', bass_nmf, 'Bass'), \n",
    "    ('vocals', vocals_nmf, 'Vocals'),\n",
    "    ('other', other_nmf, 'Other')\n",
    "]\n",
    "\n",
    "print(\"\\n=== NMF SPECTROGRAM COMPARISONS ===\\n\")\n",
    "\n",
    "for stem_key, separated_audio, stem_display_name in stems_info_nmf:\n",
    "    if stem_key in original_stems:\n",
    "        print(f\"Comparing {stem_display_name} (NMF)...\")\n",
    "        plot_spectrogram_comparison(\n",
    "            original_stems[stem_key], \n",
    "            separated_audio, \n",
    "            stem_display_name.lower(),\n",
    "            sources_nmf['sr'],\n",
    "            \"Ground Truth\",\n",
    "            \"NMF Separated\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Warning: {stem_key} not found in original stems\")\n",
    "\n",
    "# Create a summary comparison plot for NMF\n",
    "print(\"\\n=== NMF SUMMARY COMPARISON ===\")\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "# Row 1: Original stems\n",
    "# Row 2: NMF separated stems\n",
    "for i, (stem_key, separated_audio, stem_display_name) in enumerate(stems_info_nmf):\n",
    "    if stem_key in original_stems:\n",
    "        # Original stem (top row)\n",
    "        original_audio = original_stems[stem_key]\n",
    "        if hasattr(original_audio, 'numpy'):\n",
    "            original_np = original_audio.numpy()\n",
    "        else:\n",
    "            original_np = original_audio\n",
    "        \n",
    "        if original_np.ndim == 2:\n",
    "            original_np = np.mean(original_np, axis=0)\n",
    "            \n",
    "        D_orig = librosa.stft(original_np)\n",
    "        S_orig_db = librosa.amplitude_to_db(np.abs(D_orig), ref=np.max)\n",
    "        \n",
    "        img1 = librosa.display.specshow(S_orig_db, sr=sources_nmf['sr'], x_axis='time', y_axis='hz', \n",
    "                                        ax=axes[0, i], cmap='viridis')\n",
    "        axes[0, i].set_title(f'Original {stem_display_name}')\n",
    "        \n",
    "        # NMF separated stem (bottom row)\n",
    "        if separated_audio.ndim == 2:\n",
    "            separated_np = np.mean(separated_audio, axis=0)\n",
    "        else:\n",
    "            separated_np = separated_audio\n",
    "            \n",
    "        min_len = min(len(original_np), len(separated_np))\n",
    "        separated_np = separated_np[:min_len]\n",
    "        \n",
    "        D_sep = librosa.stft(separated_np)\n",
    "        S_sep_db = librosa.amplitude_to_db(np.abs(D_sep), ref=np.max)\n",
    "        \n",
    "        img2 = librosa.display.specshow(S_sep_db, sr=sources_nmf['sr'], x_axis='time', y_axis='hz', \n",
    "                                        ax=axes[1, i], cmap='viridis')\n",
    "        axes[1, i].set_title(f'NMF Separated {stem_display_name}')\n",
    "        \n",
    "        # Add colorbars\n",
    "        plt.colorbar(img1, ax=axes[0, i], format='%+2.0f dB')\n",
    "        plt.colorbar(img2, ax=axes[1, i], format='%+2.0f dB')\n",
    "\n",
    "plt.suptitle('NMF Spectrogram Comparison: Original vs Separated Stems', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute SDR for each separated source\n",
    "sdr_drums_nmf = compute_sdr(mixture, sources_nmf['drums'], sources_nmf['sr'])\n",
    "sdr_bass_nmf = compute_sdr(mixture, sources_nmf['bass'], sources_nmf['sr'])\n",
    "sdr_vocals_nmf = compute_sdr(mixture, sources_nmf['vocals'], sources_nmf['sr'])\n",
    "sdr_other_nmf = compute_sdr(mixture, sources_nmf['other'], sources_nmf['sr'])\n",
    "\n",
    "print(\"\\n=== NMF SDR RESULTS ===\")\n",
    "print(f\"SDR for Drums: {sdr_drums_nmf:.2f} dB\")\n",
    "print(f\"SDR for Bass: {sdr_bass_nmf:.2f} dB\")\n",
    "print(f\"SDR for Vocals: {sdr_vocals_nmf:.2f} dB\")\n",
    "print(f\"SDR for Other: {sdr_other_nmf:.2f} dB\")\n",
    "\n",
    "# Optional: Create a side-by-side comparison between DSP and NMF methods\n",
    "print(\"\\n=== DSP vs NMF COMPARISON ===\")\n",
    "fig, axes = plt.subplots(3, 4, figsize=(24, 15))\n",
    "\n",
    "# Get DSP results for comparison (assuming you ran the DSP separation earlier)\n",
    "if 'sources' in locals():\n",
    "    stems_comparison = [\n",
    "        ('drums', drums, drums_nmf, 'Drums'),\n",
    "        ('bass', bass, bass_nmf, 'Bass'),\n",
    "        ('vocals', vocals, vocals_nmf, 'Vocals'),\n",
    "        ('other', other, other_nmf, 'Other')\n",
    "    ]\n",
    "    \n",
    "    for i, (stem_key, dsp_audio, nmf_audio, stem_display_name) in enumerate(stems_comparison):\n",
    "        if stem_key in original_stems:\n",
    "            # Original stem (top row)\n",
    "            original_audio = original_stems[stem_key]\n",
    "            if hasattr(original_audio, 'numpy'):\n",
    "                original_np = original_audio.numpy()\n",
    "            else:\n",
    "                original_np = original_audio\n",
    "            \n",
    "            if original_np.ndim == 2:\n",
    "                original_np = np.mean(original_np, axis=0)\n",
    "                \n",
    "            D_orig = librosa.stft(original_np)\n",
    "            S_orig_db = librosa.amplitude_to_db(np.abs(D_orig), ref=np.max)\n",
    "            \n",
    "            img1 = librosa.display.specshow(S_orig_db, sr=sources_nmf['sr'], x_axis='time', y_axis='hz', \n",
    "                                            ax=axes[0, i], cmap='viridis')\n",
    "            axes[0, i].set_title(f'Original {stem_display_name}')\n",
    "            \n",
    "            # DSP separated stem (middle row)\n",
    "            if dsp_audio.ndim == 2:\n",
    "                dsp_np = np.mean(dsp_audio, axis=0)\n",
    "            else:\n",
    "                dsp_np = dsp_audio\n",
    "            \n",
    "            min_len_all = min(len(original_np), len(dsp_np), len(nmf_audio))\n",
    "            dsp_np = dsp_np[:min_len_all]\n",
    "            \n",
    "            D_dsp = librosa.stft(dsp_np)\n",
    "            S_dsp_db = librosa.amplitude_to_db(np.abs(D_dsp), ref=np.max)\n",
    "            \n",
    "            img2 = librosa.display.specshow(S_dsp_db, sr=sources_nmf['sr'], x_axis='time', y_axis='hz', \n",
    "                                            ax=axes[1, i], cmap='viridis')\n",
    "            axes[1, i].set_title(f'DSP Separated {stem_display_name}')\n",
    "            \n",
    "            # NMF separated stem (bottom row)\n",
    "            if nmf_audio.ndim == 2:\n",
    "                nmf_np = np.mean(nmf_audio, axis=0)\n",
    "            else:\n",
    "                nmf_np = nmf_audio\n",
    "                \n",
    "            nmf_np = nmf_np[:min_len_all]\n",
    "            \n",
    "            D_nmf = librosa.stft(nmf_np)\n",
    "            S_nmf_db = librosa.amplitude_to_db(np.abs(D_nmf), ref=np.max)\n",
    "            \n",
    "            img3 = librosa.display.specshow(S_nmf_db, sr=sources_nmf['sr'], x_axis='time', y_axis='hz', \n",
    "                                            ax=axes[2, i], cmap='viridis')\n",
    "            axes[2, i].set_title(f'NMF Separated {stem_display_name}')\n",
    "            \n",
    "            # Add colorbars\n",
    "            plt.colorbar(img1, ax=axes[0, i], format='%+2.0f dB')\n",
    "            plt.colorbar(img2, ax=axes[1, i], format='%+2.0f dB')\n",
    "            plt.colorbar(img3, ax=axes[2, i], format='%+2.0f dB')\n",
    "\n",
    "    plt.suptitle('Method Comparison: Original vs DSP vs NMF Separation', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Compare SDR values\n",
    "    print(\"\\n=== SDR COMPARISON: DSP vs NMF ===\")\n",
    "    print(f\"{'Stem':<8} {'DSP SDR (dB)':<12} {'NMF SDR (dB)':<12} {'Difference':<12}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    dsp_sdrs = [sdr_drums, sdr_bass, sdr_vocals, sdr_other]\n",
    "    nmf_sdrs = [sdr_drums_nmf, sdr_bass_nmf, sdr_vocals_nmf, sdr_other_nmf]\n",
    "    stem_names = ['Drums', 'Bass', 'Vocals', 'Other']\n",
    "    \n",
    "    for stem, dsp_sdr, nmf_sdr in zip(stem_names, dsp_sdrs, nmf_sdrs):\n",
    "        diff = nmf_sdr - dsp_sdr\n",
    "        print(f\"{stem:<8} {dsp_sdr:>8.2f}    {nmf_sdr:>8.2f}    {diff:>+8.2f}\")\n",
    "else:\n",
    "    print(\"DSP separation results not found. Run DSP separation first for comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2488d",
   "metadata": {},
   "source": [
    "Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56543dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchmetrics import SignalDistortionRatio\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2563f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "# Calculate average SDR, SIR, SAR and their standard deviations for each stem across all tracks\n",
    "stems = ['drums', 'vocals', 'bass', 'other']\n",
    "average_sdr = {stem: [] for stem in stems}\n",
    "average_sir = {stem: [] for stem in stems}\n",
    "average_sar = {stem: [] for stem in stems}\n",
    "\n",
    "track_folders = list(dataset_dict.keys())\n",
    "print(f\"Processing all stems simultaneously - Total tracks: {len(track_folders)}\")\n",
    "\n",
    "for idx, track_folder in enumerate(tqdm.tqdm(track_folders, desc=\"Processing tracks\")):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n[{idx+1}/{len(track_folders)}] Processing {track_folder}...\")\n",
    "        \n",
    "        mixture_path = os.path.join(\"/Users/alessandromanattini/Desktop/MAE/SELECTED TOPIC/PROJECT STMAE/musdb18hq_trimmed\", track_folder, \"new_mixture.wav\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(mixture_path):\n",
    "            print(f\"Skipping {track_folder}: mixture file not found\")\n",
    "            continue\n",
    "        \n",
    "        # Perform source separation once per track\n",
    "        print(f\"Starting source separation for {track_folder}...\")\n",
    "        separation_start = time.time()\n",
    "        \n",
    "        try:\n",
    "            separated_sources = separate_sources_v2(mixture_path)\n",
    "            separation_time = time.time() - separation_start\n",
    "            print(f\"Source separation completed in {separation_time:.2f}s\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR in source separation for {track_folder}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Prepare all reference and estimated sources\n",
    "        ref_sources = []\n",
    "        est_sources = []\n",
    "        available_stems = []\n",
    "        \n",
    "        for stem in stems:\n",
    "            if stem not in dataset_dict[track_folder]:\n",
    "                print(f\"Warning: {stem} not found in ground truth for {track_folder}\")\n",
    "                continue\n",
    "            \n",
    "            if stem not in separated_sources:\n",
    "                print(f\"Warning: {stem} not found in separated sources for {track_folder}\")\n",
    "                continue\n",
    "                \n",
    "            ref_stem = dataset_dict[track_folder][stem]\n",
    "            est_stem = separated_sources[stem]\n",
    "            \n",
    "            # Convert to tensors and handle dimensions\n",
    "            ref_tensor = torch.tensor(ref_stem, dtype=torch.float32)\n",
    "            est_tensor = torch.tensor(est_stem, dtype=torch.float32)\n",
    "            \n",
    "            # Handle dimension mismatches\n",
    "            if ref_tensor.dim() == 2:\n",
    "                ref_tensor = torch.mean(ref_tensor, dim=0)\n",
    "            if est_tensor.dim() == 2:\n",
    "                est_tensor = torch.mean(est_tensor, dim=0)\n",
    "            \n",
    "            # Ensure same length\n",
    "            min_len = min(len(ref_tensor), len(est_tensor))\n",
    "            ref_tensor = ref_tensor[:min_len]\n",
    "            est_tensor = est_tensor[:min_len]\n",
    "            \n",
    "            # Convert to numpy\n",
    "            ref_np = ref_tensor.numpy().astype(np.float64)\n",
    "            est_np = est_tensor.numpy().astype(np.float64)\n",
    "            \n",
    "            # Check energy threshold\n",
    "            energy_threshold = 1e-6\n",
    "            ref_energy = np.mean(ref_np**2)\n",
    "            est_energy = np.mean(est_np**2)\n",
    "            \n",
    "            if ref_energy < energy_threshold or est_energy < energy_threshold:\n",
    "                print(f\"Skipping {stem} in {track_folder}: insufficient energy\")\n",
    "                continue\n",
    "            \n",
    "            ref_sources.append(ref_np)\n",
    "            est_sources.append(est_np)\n",
    "            available_stems.append(stem)\n",
    "        \n",
    "        # Only proceed if we have multiple sources (needed for SIR calculation)\n",
    "        if len(ref_sources) < 2:\n",
    "            print(f\"Skipping {track_folder}: need at least 2 sources for proper BSS evaluation, got {len(ref_sources)}\")\n",
    "            continue\n",
    "        \n",
    "        # Convert to numpy arrays for mir_eval\n",
    "        ref_sources = np.array(ref_sources)\n",
    "        est_sources = np.array(est_sources)\n",
    "        \n",
    "        print(f\"Evaluating BSS metrics for {len(available_stems)} sources...\")\n",
    "        print(f\"Reference shape: {ref_sources.shape}, Estimated shape: {est_sources.shape}\")\n",
    "        \n",
    "        try:\n",
    "            # Compute BSS metrics for all sources simultaneously\n",
    "            sdr, sir, sar, perm = bss_eval_sources(\n",
    "                ref_sources, \n",
    "                est_sources, \n",
    "                compute_permutation=True  # Allow permutation to find best matching\n",
    "            )\n",
    "            \n",
    "            print(f\"BSS evaluation successful, permutation: {perm}\")\n",
    "            \n",
    "            # Store results for each available stem\n",
    "            for i, stem in enumerate(available_stems):\n",
    "                # Use permutation to get correct mapping\n",
    "                perm_idx = perm[i] if len(perm) > i else i\n",
    "                \n",
    "                if i < len(sdr) and np.isfinite(sdr[i]):\n",
    "                    average_sdr[stem].append(float(sdr[i]))\n",
    "                if i < len(sir) and np.isfinite(sir[i]):\n",
    "                    average_sir[stem].append(float(sir[i]))\n",
    "                if i < len(sar) and np.isfinite(sar[i]):\n",
    "                    average_sar[stem].append(float(sar[i]))\n",
    "                \n",
    "                print(f\"{stem}: SDR={sdr[i]:.3f}, SIR={sir[i]:.3f}, SAR={sar[i]:.3f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR in BSS evaluation for {track_folder}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"Interrupted by user at {track_folder}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"UNEXPECTED ERROR processing {track_folder}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Track {track_folder} completed in {elapsed_time:.2f}s\")\n",
    "\n",
    "# Calculate final statistics\n",
    "final_sdr = {}\n",
    "final_sir = {}\n",
    "final_sar = {}\n",
    "std_sdr = {}\n",
    "std_sir = {}\n",
    "std_sar = {}\n",
    "\n",
    "for stem in stems:\n",
    "    final_sdr[stem] = np.mean(average_sdr[stem]) if average_sdr[stem] else np.nan\n",
    "    std_sdr[stem] = np.std(average_sdr[stem]) if len(average_sdr[stem]) > 1 else 0\n",
    "    \n",
    "    final_sir[stem] = np.mean(average_sir[stem]) if average_sir[stem] else np.nan\n",
    "    std_sir[stem] = np.std(average_sir[stem]) if len(average_sir[stem]) > 1 else 0\n",
    "    \n",
    "    final_sar[stem] = np.mean(average_sar[stem]) if average_sar[stem] else np.nan\n",
    "    std_sar[stem] = np.std(average_sar[stem]) if len(average_sar[stem]) > 1 else 0\n",
    "    \n",
    "    print(f\"\\n{stem.upper()}: {len(average_sdr[stem])} valid measurements\")\n",
    "    print(f\"  SDR: {final_sdr[stem]:.3f} ± {std_sdr[stem]:.3f}\")\n",
    "    print(f\"  SIR: {final_sir[stem]:.3f} ± {std_sir[stem]:.3f}\")\n",
    "    print(f\"  SAR: {final_sar[stem]:.3f} ± {std_sar[stem]:.3f}\")\n",
    "\n",
    "# Verify metrics are different\n",
    "print(\"\\nSanity check - Are metrics different?\")\n",
    "for stem in stems:\n",
    "    if not np.isnan(final_sdr[stem]) and not np.isnan(final_sir[stem]) and not np.isnan(final_sar[stem]):\n",
    "        sdr_sir_diff = abs(final_sdr[stem] - final_sir[stem]) > 0.001\n",
    "        sdr_sar_diff = abs(final_sdr[stem] - final_sar[stem]) > 0.001\n",
    "        sir_sar_diff = abs(final_sir[stem] - final_sar[stem]) > 0.001\n",
    "        print(f\"{stem}: SDR≠SIR: {sdr_sir_diff}, SDR≠SAR: {sdr_sar_diff}, SIR≠SAR: {sir_sar_diff}\")\n",
    "\n",
    "print(\"Evaluation completed! Generating plots...\")\n",
    "\n",
    "# PLOTTING CODE\n",
    "# Create subplot for all three metrics with error bars\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Colors for each stem\n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "\n",
    "# Helper function to handle NaN values in plotting\n",
    "def safe_plot_bars(ax, keys, values, errors, title, ylabel, color_list):\n",
    "    # Replace NaN with 0 for plotting\n",
    "    plot_values = [v if not np.isnan(v) else 0 for v in values]\n",
    "    plot_errors = [e if not np.isnan(e) else 0 for e in errors]\n",
    "    \n",
    "    bars = ax.bar(keys, plot_values, yerr=plot_errors, \n",
    "                  capsize=5, color=color_list, alpha=0.7)\n",
    "    ax.set_xlabel('Stem Category')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val, err in zip(bars, values, errors):\n",
    "        if not np.isnan(val):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + err + 0.1, \n",
    "                   f'{val:.2f}±{err:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "        else:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, 0.1, \n",
    "                   'NaN', ha='center', va='bottom', fontsize=9, color='red')\n",
    "\n",
    "# Plot all metrics\n",
    "safe_plot_bars(axes[0], final_sdr.keys(), list(final_sdr.values()), \n",
    "               list(std_sdr.values()), 'Average SDR Performance by Stem Category', \n",
    "               'Average SDR (dB)', colors)\n",
    "\n",
    "safe_plot_bars(axes[1], final_sir.keys(), list(final_sir.values()), \n",
    "               list(std_sir.values()), 'Average SIR Performance by Stem Category', \n",
    "               'Average SIR (dB)', colors)\n",
    "\n",
    "safe_plot_bars(axes[2], final_sar.keys(), list(final_sar.values()), \n",
    "               list(std_sar.values()), 'Average SAR Performance by Stem Category', \n",
    "               'Average SAR (dB)', colors)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed results with standard deviations\n",
    "print(\"Average metrics with standard deviations by stem:\")\n",
    "print(\"=\" * 60)\n",
    "for stem in stems:\n",
    "    print(f\"{stem.upper()}:\")\n",
    "    sdr_str = f\"{final_sdr[stem]:.4f} ± {std_sdr[stem]:.4f}\" if not np.isnan(final_sdr[stem]) else \"NaN\"\n",
    "    sir_str = f\"{final_sir[stem]:.4f} ± {std_sir[stem]:.4f}\" if not np.isnan(final_sir[stem]) else \"NaN\"\n",
    "    sar_str = f\"{final_sar[stem]:.4f} ± {std_sar[stem]:.4f}\" if not np.isnan(final_sar[stem]) else \"NaN\"\n",
    "    \n",
    "    print(f\"  SDR: {sdr_str} dB\")\n",
    "    print(f\"  SIR: {sir_str} dB\") \n",
    "    print(f\"  SAR: {sar_str} dB\")\n",
    "    print()\n",
    "\n",
    "# Create a comprehensive summary table\n",
    "print(\"Summary Table with Standard Deviations:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Stem':<8} {'SDR (dB)':<18} {'SIR (dB)':<18} {'SAR (dB)':<18}\")\n",
    "print(f\"{'':8} {'Mean ± Std':<18} {'Mean ± Std':<18} {'Mean ± Std':<18}\")\n",
    "print(\"-\" * 80)\n",
    "for stem in stems:\n",
    "    sdr_cell = f\"{final_sdr[stem]:>6.2f}±{std_sdr[stem]:<6.2f}\" if not np.isnan(final_sdr[stem]) else \"    NaN±  NaN\"\n",
    "    sir_cell = f\"{final_sir[stem]:>6.2f}±{std_sir[stem]:<6.2f}\" if not np.isnan(final_sir[stem]) else \"    NaN±  NaN\"\n",
    "    sar_cell = f\"{final_sar[stem]:>6.2f}±{std_sar[stem]:<6.2f}\" if not np.isnan(final_sar[stem]) else \"    NaN±  NaN\"\n",
    "    \n",
    "    print(f\"{stem:<8} {sdr_cell:<18} {sir_cell:<18} {sar_cell:<18}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "# Calculate average SDR, SIR, SAR and their standard deviations for each stem across all tracks\n",
    "stems = ['drums', 'vocals', 'bass', 'other']\n",
    "average_sdr = {stem: [] for stem in stems}\n",
    "average_sir = {stem: [] for stem in stems}\n",
    "average_sar = {stem: [] for stem in stems}\n",
    "\n",
    "track_folders = list(dataset_dict.keys())\n",
    "print(f\"Processing all stems simultaneously - Total tracks: {len(track_folders)}\")\n",
    "\n",
    "for idx, track_folder in enumerate(tqdm.tqdm(track_folders, desc=\"Processing tracks\")):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n[{idx+1}/{len(track_folders)}] Processing {track_folder}...\")\n",
    "        \n",
    "        mixture_path = os.path.join(\"/Users/alessandromanattini/Desktop/MAE/SELECTED TOPIC/PROJECT STMAE/musdb18hq_trimmed\", track_folder, \"new_mixture.wav\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(mixture_path):\n",
    "            print(f\"Skipping {track_folder}: mixture file not found\")\n",
    "            continue\n",
    "        \n",
    "        # Perform source separation once per track\n",
    "        print(f\"Starting source separation for {track_folder}...\")\n",
    "        separation_start = time.time()\n",
    "        \n",
    "        try:\n",
    "            separated_sources = separate_sources_v3(mixture_path)\n",
    "            separation_time = time.time() - separation_start\n",
    "            print(f\"Source separation completed in {separation_time:.2f}s\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR in source separation for {track_folder}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Prepare all reference and estimated sources\n",
    "        ref_sources = []\n",
    "        est_sources = []\n",
    "        available_stems = []\n",
    "        \n",
    "        for stem in stems:\n",
    "            if stem not in dataset_dict[track_folder]:\n",
    "                print(f\"Warning: {stem} not found in ground truth for {track_folder}\")\n",
    "                continue\n",
    "            \n",
    "            if stem not in separated_sources:\n",
    "                print(f\"Warning: {stem} not found in separated sources for {track_folder}\")\n",
    "                continue\n",
    "                \n",
    "            ref_stem = dataset_dict[track_folder][stem]\n",
    "            est_stem = separated_sources[stem]\n",
    "            \n",
    "            # Convert to tensors and handle dimensions\n",
    "            ref_tensor = torch.tensor(ref_stem, dtype=torch.float32)\n",
    "            est_tensor = torch.tensor(est_stem, dtype=torch.float32)\n",
    "            \n",
    "            # Handle dimension mismatches\n",
    "            if ref_tensor.dim() == 2:\n",
    "                ref_tensor = torch.mean(ref_tensor, dim=0)\n",
    "            if est_tensor.dim() == 2:\n",
    "                est_tensor = torch.mean(est_tensor, dim=0)\n",
    "            \n",
    "            # Ensure same length\n",
    "            min_len = min(len(ref_tensor), len(est_tensor))\n",
    "            ref_tensor = ref_tensor[:min_len]\n",
    "            est_tensor = est_tensor[:min_len]\n",
    "            \n",
    "            # Convert to numpy\n",
    "            ref_np = ref_tensor.numpy().astype(np.float64)\n",
    "            est_np = est_tensor.numpy().astype(np.float64)\n",
    "            \n",
    "            # Check energy threshold\n",
    "            energy_threshold = 1e-6\n",
    "            ref_energy = np.mean(ref_np**2)\n",
    "            est_energy = np.mean(est_np**2)\n",
    "            \n",
    "            if ref_energy < energy_threshold or est_energy < energy_threshold:\n",
    "                print(f\"Skipping {stem} in {track_folder}: insufficient energy\")\n",
    "                continue\n",
    "            \n",
    "            ref_sources.append(ref_np)\n",
    "            est_sources.append(est_np)\n",
    "            available_stems.append(stem)\n",
    "        \n",
    "        # Only proceed if we have multiple sources (needed for SIR calculation)\n",
    "        if len(ref_sources) < 2:\n",
    "            print(f\"Skipping {track_folder}: need at least 2 sources for proper BSS evaluation, got {len(ref_sources)}\")\n",
    "            continue\n",
    "        \n",
    "        # Convert to numpy arrays for mir_eval\n",
    "        ref_sources = np.array(ref_sources)\n",
    "        est_sources = np.array(est_sources)\n",
    "        \n",
    "        print(f\"Evaluating BSS metrics for {len(available_stems)} sources...\")\n",
    "        print(f\"Reference shape: {ref_sources.shape}, Estimated shape: {est_sources.shape}\")\n",
    "        \n",
    "        try:\n",
    "            # Compute BSS metrics for all sources simultaneously\n",
    "            sdr, sir, sar, perm = bss_eval_sources(\n",
    "                ref_sources, \n",
    "                est_sources, \n",
    "                compute_permutation=True  # Allow permutation to find best matching\n",
    "            )\n",
    "            \n",
    "            print(f\"BSS evaluation successful, permutation: {perm}\")\n",
    "            \n",
    "            # Store results for each available stem\n",
    "            for i, stem in enumerate(available_stems):\n",
    "                # Use permutation to get correct mapping\n",
    "                perm_idx = perm[i] if len(perm) > i else i\n",
    "                \n",
    "                if i < len(sdr) and np.isfinite(sdr[i]):\n",
    "                    average_sdr[stem].append(float(sdr[i]))\n",
    "                if i < len(sir) and np.isfinite(sir[i]):\n",
    "                    average_sir[stem].append(float(sir[i]))\n",
    "                if i < len(sar) and np.isfinite(sar[i]):\n",
    "                    average_sar[stem].append(float(sar[i]))\n",
    "                \n",
    "                print(f\"{stem}: SDR={sdr[i]:.3f}, SIR={sir[i]:.3f}, SAR={sar[i]:.3f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR in BSS evaluation for {track_folder}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"Interrupted by user at {track_folder}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"UNEXPECTED ERROR processing {track_folder}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Track {track_folder} completed in {elapsed_time:.2f}s\")\n",
    "\n",
    "# Calculate final statistics\n",
    "final_sdr = {}\n",
    "final_sir = {}\n",
    "final_sar = {}\n",
    "std_sdr = {}\n",
    "std_sir = {}\n",
    "std_sar = {}\n",
    "\n",
    "for stem in stems:\n",
    "    final_sdr[stem] = np.mean(average_sdr[stem]) if average_sdr[stem] else np.nan\n",
    "    std_sdr[stem] = np.std(average_sdr[stem]) if len(average_sdr[stem]) > 1 else 0\n",
    "    \n",
    "    final_sir[stem] = np.mean(average_sir[stem]) if average_sir[stem] else np.nan\n",
    "    std_sir[stem] = np.std(average_sir[stem]) if len(average_sir[stem]) > 1 else 0\n",
    "    \n",
    "    final_sar[stem] = np.mean(average_sar[stem]) if average_sar[stem] else np.nan\n",
    "    std_sar[stem] = np.std(average_sar[stem]) if len(average_sar[stem]) > 1 else 0\n",
    "    \n",
    "    print(f\"\\n{stem.upper()}: {len(average_sdr[stem])} valid measurements\")\n",
    "    print(f\"  SDR: {final_sdr[stem]:.3f} ± {std_sdr[stem]:.3f}\")\n",
    "    print(f\"  SIR: {final_sir[stem]:.3f} ± {std_sir[stem]:.3f}\")\n",
    "    print(f\"  SAR: {final_sar[stem]:.3f} ± {std_sar[stem]:.3f}\")\n",
    "\n",
    "# Verify metrics are different\n",
    "print(\"\\nSanity check - Are metrics different?\")\n",
    "for stem in stems:\n",
    "    if not np.isnan(final_sdr[stem]) and not np.isnan(final_sir[stem]) and not np.isnan(final_sar[stem]):\n",
    "        sdr_sir_diff = abs(final_sdr[stem] - final_sir[stem]) > 0.001\n",
    "        sdr_sar_diff = abs(final_sdr[stem] - final_sar[stem]) > 0.001\n",
    "        sir_sar_diff = abs(final_sir[stem] - final_sar[stem]) > 0.001\n",
    "        print(f\"{stem}: SDR≠SIR: {sdr_sir_diff}, SDR≠SAR: {sdr_sar_diff}, SIR≠SAR: {sir_sar_diff}\")\n",
    "\n",
    "print(\"Evaluation completed! Generating plots...\")\n",
    "\n",
    "# PLOTTING CODE\n",
    "# Create subplot for all three metrics with error bars\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Colors for each stem\n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "\n",
    "# Helper function to handle NaN values in plotting\n",
    "def safe_plot_bars(ax, keys, values, errors, title, ylabel, color_list):\n",
    "    # Replace NaN with 0 for plotting\n",
    "    plot_values = [v if not np.isnan(v) else 0 for v in values]\n",
    "    plot_errors = [e if not np.isnan(e) else 0 for e in errors]\n",
    "    \n",
    "    bars = ax.bar(keys, plot_values, yerr=plot_errors, \n",
    "                  capsize=5, color=color_list, alpha=0.7)\n",
    "    ax.set_xlabel('Stem Category')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val, err in zip(bars, values, errors):\n",
    "        if not np.isnan(val):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + err + 0.1, \n",
    "                   f'{val:.2f}±{err:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "        else:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, 0.1, \n",
    "                   'NaN', ha='center', va='bottom', fontsize=9, color='red')\n",
    "\n",
    "# Plot all metrics\n",
    "safe_plot_bars(axes[0], final_sdr.keys(), list(final_sdr.values()), \n",
    "               list(std_sdr.values()), 'Average SDR Performance by Stem Category', \n",
    "               'Average SDR (dB)', colors)\n",
    "\n",
    "safe_plot_bars(axes[1], final_sir.keys(), list(final_sir.values()), \n",
    "               list(std_sir.values()), 'Average SIR Performance by Stem Category', \n",
    "               'Average SIR (dB)', colors)\n",
    "\n",
    "safe_plot_bars(axes[2], final_sar.keys(), list(final_sar.values()), \n",
    "               list(std_sar.values()), 'Average SAR Performance by Stem Category', \n",
    "               'Average SAR (dB)', colors)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed results with standard deviations\n",
    "print(\"Average metrics with standard deviations by stem:\")\n",
    "print(\"=\" * 60)\n",
    "for stem in stems:\n",
    "    print(f\"{stem.upper()}:\")\n",
    "    sdr_str = f\"{final_sdr[stem]:.4f} ± {std_sdr[stem]:.4f}\" if not np.isnan(final_sdr[stem]) else \"NaN\"\n",
    "    sir_str = f\"{final_sir[stem]:.4f} ± {std_sir[stem]:.4f}\" if not np.isnan(final_sir[stem]) else \"NaN\"\n",
    "    sar_str = f\"{final_sar[stem]:.4f} ± {std_sar[stem]:.4f}\" if not np.isnan(final_sar[stem]) else \"NaN\"\n",
    "    \n",
    "    print(f\"  SDR: {sdr_str} dB\")\n",
    "    print(f\"  SIR: {sir_str} dB\") \n",
    "    print(f\"  SAR: {sar_str} dB\")\n",
    "    print()\n",
    "\n",
    "# Create a comprehensive summary table\n",
    "print(\"Summary Table with Standard Deviations:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Stem':<8} {'SDR (dB)':<18} {'SIR (dB)':<18} {'SAR (dB)':<18}\")\n",
    "print(f\"{'':8} {'Mean ± Std':<18} {'Mean ± Std':<18} {'Mean ± Std':<18}\")\n",
    "print(\"-\" * 80)\n",
    "for stem in stems:\n",
    "    sdr_cell = f\"{final_sdr[stem]:>6.2f}±{std_sdr[stem]:<6.2f}\" if not np.isnan(final_sdr[stem]) else \"    NaN±  NaN\"\n",
    "    sir_cell = f\"{final_sir[stem]:>6.2f}±{std_sir[stem]:<6.2f}\" if not np.isnan(final_sir[stem]) else \"    NaN±  NaN\"\n",
    "    sar_cell = f\"{final_sar[stem]:>6.2f}±{std_sar[stem]:<6.2f}\" if not np.isnan(final_sar[stem]) else \"    NaN±  NaN\"\n",
    "    \n",
    "    print(f\"{stem:<8} {sdr_cell:<18} {sir_cell:<18} {sar_cell:<18}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
